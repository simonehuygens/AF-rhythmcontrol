---
title: "Disease model for rhythm control strategies in symptomatic AF patients"
author: "Simone Huygens and Matthijs Versteegh on behalf of Zorginstituut Nederland"
date: '2025-05-07'
output: word_document
---

For more information on the input parameters and methods, we refer to the technical report.

# 01 Settings and load required packages, functions and data

# 01.0 Clear memory
```{r}
rm(list = ls())     # clear memory (removes all the variables from the workspace)
options(scipen=999) # disable scientific notation
set.seed(1)         # set the seed for random number generation

```

## 01.1 Load packages
```{r, warning=F, message=F, include=FALSE}
if (!require('pacman')) install.packages('pacman'); library(pacman) # use this package to conveniently install other packages

# load (install if required) packages from CRAN
p_load("here", "dplyr", "ggplot2", "MASS", "tictoc", "tidyr", "survival", "flexsurv", "survminer", 
       "doParallel", "betareg", "truncnorm", "parallel", "foreach", "Matrix", "splines", "flextable", "officer")

# load (install if required) packages from GitHub
# install_github("DARTH-git/dampack", force = TRUE) Uncomment if there is a newer version
# install_github("DARTH-git/darthtools", force = TRUE) Uncomment if there is a newer version
p_load_gh("DARTH-git/dampack", "DARTH-git/darthtools", "DARTH-git/dectree")

```

## 01.2 Settings
```{r}

# Model settings 
min_age            <- 18                           # min age: only include adults
max_age            <- 108                          # max age based on max in Human Mortality Database
cl                 <- 0.5                          # cycle length in years: should be 0.5 because not all 
                                                   # input parameters are automatically varied (i.e. TTE Vektis)
n_t                <- (max_age-min_age)/cl         # time horizon in cycles
n_cycles           <- n_t                          # number of cycles 
n_i                <- 50000                        # number of simulated individuals (n_i >= 50,000 for stable model results)
v_n                <- c("SFAF", "SAF", "D")        # model states names
v_names_states     <- v_n                          # variable needed for plot_trace_microsim
n_states           <- n_s <- length(v_n)           # the number of health states
wtp                <- 20000                        # willingness to pay threshold (based on proportional shortfall AF)
d_rc               <- 0.030                        # discount rate costs
d_re               <- 0.015                        # discount rate effects
d_rc               <- (1+d_rc)^cl-1                # discount rate costs to x-weekly 
d_re               <- (1+d_re)^cl-1                # discount rate effects to x-weekly 
v_dwc              <- 1 / ((1 + d_rc) ^ (0:n_t))   # per period discount weight costs
v_dwe              <- 1 / ((1 + d_re) ^ (0:n_t))   # per period discount weight effects
v_wcc              <- darthtools::gen_wcc(n_cycles = n_t, method = "Simpson1/3")  # within-cycle correction (WCC) 
v_names_lines      <- c("TRT1", "TRT2", "TRT3", "TRT4", "TRT5", "TRT6", "no-treatment", "D") # line names

# Base case or scenario
# The scenario "TTE_2CV" includes the time to event data from the health insurers declaration data (Vektis) of the scenario analysis where AF symptoms are defined as re-ablation, His-ablation, MAZE procedure, switch to amiodarone or at least 2 cardioversions within one year (i.e. single cardioversions without a second cardioversion within a year are not counted as recurrence of AF symptoms). In the base case all cardioversions are counted as recurrence of AF symptoms after which a treatment switch will be incurred in the model.

scenario <- "basecase" # "basecase" or "TTE_2CV"

```

## 01.3 Load functions
```{r}
# Load generic functions
source(here::here("functions", "functions.R"))

```

# 02 Define parameter input values
```{r}
# 02 Defineparameter input values
#### PATIENT CHARACTERISTICS ####
n_survived         <- 30182                                         # de Mol et al. 2022 (NHR 2013-2020) Table 1
n_deceased         <- 15                                            # de Mol et al. 2022 (NHR 2013-2020) Table 1
n_total            <- n_survived+n_deceased                         # de Mol et al. 2022 (NHR 2013-2020) Table 1 
age                <- ((61.4*n_survived)+(65.9*n_deceased))/n_total # de Mol et al. 2022 (NHR 2013-2020) Table 1 
sd_age             <- ((9.8*n_survived)+(7.1*n_deceased))/n_total   # de Mol et al. 2022 (NHR 2013-2020) Table 1 
n_female           <- 9816+7                                        # de Mol et al. 2022 (NHR 2013-2020) Table 1 (survived + deceased)
n_male             <- n_total-n_female                              
prop_female        <- n_female/(n_female+n_male)
n_paroxysmal       <- 19527+11     # proportion paroxysmal AF: de Mol et al. 2022 (NHR 2013-2020) Table 1 (survived + deceased)
n_persistent       <- 7300+3+542+0 # proportion persistent AF: de Mol et al. 2022 (NHR 2013-2020) Table 1 (survived + deceased)
prop_parox         <- n_paroxysmal/(n_paroxysmal+n_persistent)

# Generate patient population (will be varied in PSA)
set.seed(2)
v_age                 <- round(rtruncnorm(n_i, min_age, max_age, age, sd_age)) 
v_Sex                 <- rbinom(n_i, 1, prop_female) 

#### CLINICAL INPUTS ####

#### Probabilities of treatment success ####
# Load results of meta-analysis Cochrane Nederland
load(here::here("input", "meta-analysis-efficacy.RData"))
load(here::here("input", "meta-analyse disc_AAD.RData"))

# Relative risks of AF recurrence AAD vs. CA (Source: meta-analysis Cochrane Nederland) 
RR_nai                 <- exp(predrema1$pred) # 1.76 95% CI 1.34-2.32. Patients naive to AAD and CA, i.e. first line. 
RR_AAD_exp_parox       <- exp(predrema2$pred) # 2.32 95% CI 1.78-3.01. Patients with paroxysmal AF exposed to AAD but naive to CA
RR_AAD_exp_pers        <- exp(predrema3$pred) # 1.62 95% CI 1.4-1.87.  Patients with persistent AF exposed to AAD but naive to CA
RR_CA_exp              <-  2.12 # CI 1.61-2.80, based on 1 study. Patients exposed to CA and naive or exposed to AAD.

# Probability of recurrence of AF after CA after 1 year 
prop_AF_CA_nai           <- plogis(predrema1i$pred) # 0.18 CI 0.08-0.35. After 1st CA in AAD/CA naive patients (Source: meta-analysis)
prop_AF_CA_AAD_exp_parox <- plogis(predrema2i$pred) # 0.26 CI 0.18-0.36. After 1st CA in AAD exposed paroxysmal AF patients (Source: meta-analysis)
prop_AF_CA_AAD_exp_pers  <- plogis(predrema3i$pred) # 0.38 CI 0.33-0.42. After 1st CA in AAD exposed persistent AF patients. (Source: meta-analysis)
prop_AF_CA_CA_exp_1      <- 0.2579740 # After 2nd CA. (Source: Vektis)
prop_AF_CA_CA_exp_2      <- 0.3292506 # After 3+ CA. (Source: Vektis)

#### Probability of recurrence of AF symptoms after CA over time ####
# Load transition probabilities for recurrence of AF symptoms based on data from the health insurers declaration data (Vektis)
if(scenario == "basecase"){
  load(here::here("input", "TTE_AF_Vektis.RData")) # survival model objects (version 17-04-2025)
  
  # Generate transition probabilities from survival model objects (requires flexsurv package 2.3.2)
  df_s_ablation1     <- summary(best_fit_ablation1, t = seq(0, n_t*cl, cl), ci = T, newdata = T)
  p_SFAF_CA_SAF_L1   <- trans_prob(df_s_ablation1[[1]]$est) # probability of recurrence of AF after first CA
  df_s_ablation2     <- summary(best_fit_ablation2, t = seq(0, n_t*cl, cl), ci = T, newdata = T)
  p_SFAF_CA_SAF_L2   <- trans_prob(df_s_ablation2[[1]]$est) # probability of recurrence of AF after second CA
  df_s_ablation3     <- summary(best_fit_ablation3, t = seq(0, n_t*cl, cl), ci = T, newdata = T)
  p_SFAF_CA_SAF_L3   <- trans_prob(df_s_ablation3[[1]]$est)
}

if(scenario == "TTE_2CV"){
  load(here::here("input", "TTE_AF_Vektis_scenario.RData")) # survival model objects (version 17-04-2025)
  
  # Generate transition probabilities from survival model objects (requires flexsurv package 2.3.2)
  df_s_ablation1     <- summary(best_fit_ablation1, t = seq(0, n_t*cl, cl), ci = T, newdata = T)
  p_SFAF_CA_SAF_L1   <- trans_prob(df_s_ablation1[[1]]$est) # probability of recurrence of AF after first CA
  df_s_ablation2     <- summary(best_fit_ablation2, t = seq(0, n_t*cl, cl), ci = T, newdata = T)
  p_SFAF_CA_SAF_L2   <- trans_prob(df_s_ablation2[[1]]$est) # probability of recurrence of AF after second CA
  p_SFAF_CA_SAF_L3   <- p_SFAF_CA_SAF_L2 # in scenario analysis the probability of recurrence of AF after is pooled for second or more CA
}

#### Probability of death ####
# Background mortality in the general population weighted by the sex distribution of the patient population
# We used 2019 to avoid bias from COVID-19
df_mort              <- read.csv(here::here("input", "sterfte_NL_2019.csv"), sep = ";", header = TRUE)
df_mort              <- df_mort[ , -c(1,5)] # remove year and total column
df_mort <- df_mort %>% # convert table from wide to long with a variable for sex
  pivot_longer(
    cols = c(Female, Male),
    names_to = "Sex",
    values_to = "r_mort"
  ) %>%
  mutate(
    Sex = ifelse(Sex == "Female", 1, 0),
    r_mort = as.numeric(r_mort)
  )
df_mort$r_mort_cl  <- df_mort$r_mort*cl # convert annual mortality rate to x-weekly mortality rate
df_mort$p_mort_cl  <- 1-exp(-df_mort$r_mort_cl)     # convert x-weekly mortality rate to probability
df_mort[df_mort$Age == 108, "p_mort_cl"] <- 1 # set mortality rate to 1 at max age to make sure everyone dies in the model

# Excess mortality in patients with AF based on Vinter et al. (2020)
# HR of 'Model adjusted for baseline covariates' of 2001-15
# We did not use 'Model adjusted for time varying covariates' because it was no proportional hazards model
HR_EM <- 2.01 # 95% CI: 1.71 to 2.36 (Vinter et al. 2020)

#### Probability of severe adverse events ####
# Discontinuation of AAD's due to adverse events
p_disc_AAD_nai <- 0.121 # Source: meta-analysis Cochrane Netherlands
p_disc_AAD_exp <- 0.225 # Source: meta-analysis Cochrane Netherlands

# Adverse events CA (Source: event rates from NHR ablation analysis tool: Behandelgroep: Katheterablatie AF, Jaar: 2023) 
n_CT_CA         <- 26   # cardiac tamponade
n_tot_CT_CA     <- 6150
p_CT_CA         <- n_CT_CA/n_tot_CT_CA
n_PP_CA         <- 25   # phrenicus paralysis
n_tot_PP_CA     <- 6211
p_PP_CA         <- n_PP_CA/n_tot_PP_CA 
n_VC_CA         <- 40   # vascular complications
n_tot_VC_CA     <- 6149
p_VC_CA         <- n_VC_CA/n_tot_VC_CA 

#### COST INPUTS ####

#### Health state costs and costs of interventions (Source: Vektis)
df_c_states  <- load(here::here("input", "c_Vektis.RData")) 

#### Future medical costs
# All costs using PAID tool, excluding costs for "Other heart diseases including pulmonary circulation" because we assume these are already included in the model in the cost inputs above. 
df_FMC                <- read.csv(here::here("input", "PAID_AF_FMC_Unrelated_Costs_2025-02-26.csv")) 
colnames(df_FMC)      <- c("Age", "last_y_m", "last_y_f", "other_y_m", "other_y_f")
df_FMC[101:121,]      <- df_FMC[nrow(df_FMC),] # repeat at age 99 for age 100-120
df_FMC$Age[101:121]   <- seq(from = 100, to = 120, by = 1)
df_FMC <- df_FMC %>%
  pivot_longer(
    cols = c(last_y_m, last_y_f, other_y_m, other_y_f),
    names_to = c(".value", "Sex"),
    names_pattern = "(.*)_(.*)$"
  ) %>%
  mutate(
    Sex = ifelse(Sex == "f", 1, 0),
    last_y = as.numeric(last_y),
    other_y = as.numeric(other_y)
  )

#### Productivity costs inputs
# Inputs are used in PrepareCosts to calculate productivity costs
# Load the regression parameters and the variance covariance matrix of relationship between EQ-5D and productivity loss
load(here::here("input", "betareg_productivity_AVATARAF_NL.RData"))

beta_reg_attendance_intercept   <- beta_reg_attendance$coefficients$mean[1]
beta_reg_attendance_SAF         <- beta_reg_attendance$coefficients$mean[2]
beta_reg_presenteeism_intercept <- beta_reg_presenteeism$coefficients$mean[1]
beta_reg_presenteeism_SAF       <- beta_reg_presenteeism$coefficients$mean[2]

# Proportion of general population working, average hours per week and hourly wage
# Calculations performed in PrepareCosts
prop_work_M        <- 0.681 # Source: CBS 2024 Netto arbeidsparticipatie tussen 45-75 jaar.
prop_work_F        <- 0.572 # Source: CBS 2024 Netto arbeidsparticipatie tussen 45-75 jaar.
v_hours_per_week_M <- 35.9  # Source: "Werkzame beroepsbevolking; arbeidsduur" CBS 2024
v_hours_per_week_F <- 27.9  # Source: "Werkzame beroepsbevolking; arbeidsduur" CBS 2024
c_hourly_wage_2022 <- 39.88 # Source: Dutch costing manual Euro 2022. 

#### Informal care costs 
# Informal care costs are based on a regression model of de Groot et al. (2023) that estimates informal care costs according to age and proximity to death
# Regression model for probability of informal care (de Groot et al. 2023)
params_ic_log_intercept   <- -1.451 # SE 0.220  
params_ic_log_female      <-  0.368 # SE 0.120  
params_ic_log_age         <-  0.054 # SE 0.008  
params_ic_log_age2        <-  0.000 # SE 0.000 
params_ic_log_T2D         <- -0.061 # SE 0.015  
params_ic_hours_intercept <-  0.497 # SE 0.198  
params_ic_hours_female    <-  0.112 # SE 0.106  
params_ic_hours_age       <-  0.019 # SE 0.005  
params_ic_hours_T2D       <- -0.034 # SE 0.011 

# Logistic regression for use of informal care
# Coefficients on log-scale: intercept, gender (female = 1), age (age-centered at 70), age2, TTD (in years)
params_ic_log   <- c(params_ic_log_intercept, params_ic_log_female, params_ic_log_age, params_ic_log_age2, params_ic_log_T2D) 
vcov_ic_log     <- read.csv(here::here("input", "vcov_ic_log.csv"), sep = ",", header = FALSE)

# Lineair regression for number of hours of informal care
# Coefficients: intercept, gender (female = 1), age  (age-centered at 70), TTD (in years)
params_ic_hours <- c(params_ic_hours_intercept, params_ic_hours_female, params_ic_hours_age, params_ic_hours_T2D)
vcov_ic_hours   <- read.csv(here::here("input", "vcov_ic_hours.csv"), sep = ",", header = FALSE)

# Inputs to calculate the average time to death and corresponding informal care costs of patients with the age of Van Den Dries et al. (i.e. 77 years)
# Calculations performed in PrepareCosts
LE_M_77              <- 10.3 # Life expectancy males of 77 years, Source: CBS
LE_F_77              <- 11.9 # Life expectancy females of 77 years, Source: CBS
c_IC_hr              <- 18.8 # Hourly costs of informal care (Source: Kostenhandleiding, 2022 Euros)
c_IC_77_AF_2yr       <- 3296.45 #SD = 321.76, 24-month costs of AF patients in Van den Dries et al. (2023) 
c_IC_77_AF_2yr_gamma <- gamma_params(c_IC_77_AF_2yr, (321.76/sqrt(425)))

#### UTILITIES INPUTS ####
#### Disutilities AF and adverse events ####
# Load utilities based on the EQ-5D-5L data in the AVATAR-AF trial using the Dutch tariff
load(here::here("input", "glm_AVATARAF_NL.RData"))

du_SAF       <- abs(unname((glm_AVATARAF_NL$coefficients[2]))) # Re-analysis of AVATAR-AF with EQ-5D-5L NL tariff based on Moss et al. 

# Assumption similar to Akerborg et al. (2012) and Reynolds et al. (2014)
du_CT_mo  <- 0.1 # Assumption disutility of 0.1 for 1 month, corrected to disutility for the cycle length in Effs
du_PP_mo  <- 0.1 # Assumption disutility of 0.1 for 1 month, corrected to disutility for the cycle length in Effs
du_VC_mo  <- 0.1 # Assumption disutility of 0.1 for 1 month, corrected to disutility for the cycle length in Effs

#### General population utilities ####
# Regression model general population by age and sex (based on Versteegh et al. 2016)
load(here::here("input", "splines_HRQoL.RData")) 
gen_pop_utility  <- "fit"
mod_splines_coef <- mod_splines$coefficients

#### STORE INPUT PARAMETERS ####
# Create a vector of variable names
v_names_params <- c("age", "sd_age", "prop_female", "v_age", "v_Sex", "prop_parox",
                    "RR_nai", "RR_AAD_exp_parox", "RR_AAD_exp_pers", "RR_CA_exp", 
                    "prop_AF_CA_nai", "prop_AF_CA_AAD_exp_parox","prop_AF_CA_AAD_exp_pers", 
                    "prop_AF_CA_CA_exp_1", "prop_AF_CA_CA_exp_2",   
                    "p_SFAF_CA_SAF_L1", "p_SFAF_CA_SAF_L2", "p_SFAF_CA_SAF_L3", 
                    "HR_EM", "p_disc_AAD_nai", "p_disc_AAD_exp",
                    "p_CT_CA", "p_PP_CA", "p_VC_CA",
                    "c_AAD", "c_CA_DBC", "c_d_before_CA", "c_d_after_CA1", "c_d_after_CA2", "c_d_SAF", "df_FMC", 
                    "prop_work_M", "prop_work_F", "v_hours_per_week_M", "v_hours_per_week_F",
                    "c_hourly_wage_2022", "params_ic_log_intercept", "params_ic_log_female", 
                    "params_ic_log_age", "params_ic_log_age2", 'params_ic_log_T2D',  "params_ic_hours_intercept",
                    "params_ic_hours_female", "params_ic_hours_age", "params_ic_hours_T2D",   
                    "beta_reg_attendance_intercept", "beta_reg_attendance_SAF", 
                    "beta_reg_presenteeism_intercept", "beta_reg_presenteeism_SAF",      
                    "LE_M_77", "LE_F_77", "c_IC_hr", "c_IC_77_AF_2yr",
                    "du_SAF", "du_CT_mo", "du_PP_mo", "du_VC_mo", 
                    "gen_pop_utility", "mod_splines_coef"
)

# Store the parameters into a list
l_params <- mget(v_names_params)
#View(l_params)

```

# 03 Functions for microsimulation
## 03.1 df_X: dataframe with individual level characteristics
Function to create the dataframe with patient characteristics
```{r}

Create_df_X <- function(l_params){
  with((l_params), {
    
    set.seed(1)
    
    # v_age and v_Sex are created in the previous section to enable variation in PSA
    v_Trt      <- rep("AAD", n_i) # Placeholder that will be overwritten in first section of MicroSim
    v_Line     <- rep(1, n_i)
    v_disc_AAD <- rep(0, n_i)
    v_CT_CA    <- rep(0, n_i)  # event counter for cardiac tamponade
    v_PP_CA    <- rep(0, n_i)  # event counter for phrenicus paralysis
    v_VC_CA    <- rep(0, n_i)  # event counter for vascular complications
    v_TH       <- rep(0, n_i)  # Treatment history: 1 if current treatment is first month of CA (for side effects)
    v_AAD_exp  <- rep(0, n_i)  # Exposed to AAD
    v_CA_exp_1 <- rep(0, n_i)  # Exposed to CA
    v_CA_exp_2 <- rep(0, n_i)  # Exposed to at least 2 CAs
    v_death    <- rep(0, n_i)  # Death
    
    
    df_X       <- data.frame(ID = 1:n_i, Age = v_age, Age_cl = v_age, Age_start = v_age, Sex = v_Sex, 
                             curTrt = v_Trt, Line = v_Line, 
                             disc_AAD = v_disc_AAD, 
                             CT_CA = v_CT_CA, PP_CA = v_PP_CA, VC_CA = v_VC_CA, 
                             TH = v_TH, AAD_exp = v_AAD_exp, CA_exp_1 = v_CA_exp_1, CA_exp_2 = v_CA_exp_2, 
                             death = v_death)
    
    return(df_X)
  })
}

```

## 03.2 Prepare probabilities 
Function to prepare probabilities based on input parameters
- Calculates weighted average of paroxysmal and persistent AF input parameters
- Calculates probabilities for AAD based on CA and RR of AAD vs. CA
- Converts probabilities to cycle length
```{r}
PrepareProbs <- function(l_params){
  
  with((l_params),{
    
    # Calculate weighted average for prop_AF_CA_AAD_exp and RR_AAD_exp
    prop_AF_CA_AAD_exp     <- expit((logit(prop_AF_CA_AAD_exp_parox)*prop_parox)+(logit(prop_AF_CA_AAD_exp_pers)*(1-prop_parox)))  
    
    # Probability of recurrence of AF after AAD after 1 year 
    RR_AAD_exp             <- exp((log(RR_AAD_exp_parox)*prop_parox)+(log(RR_AAD_exp_pers)*(1-prop_parox))) # weighted RR 
    
    # Based on proportion of recurrence of AF after CA multiplied with relative risk of AAD vs. CA
    prop_AF_AAD_nai        <- prop_AF_CA_nai*RR_nai    
    prop_AF_AAD_AAD_exp    <- prop_AF_CA_AAD_exp*RR_AAD_exp
    prop_AF_AAD_CA_exp_1   <- prop_AF_CA_CA_exp_1*RR_CA_exp
    prop_AF_AAD_CA_exp_2   <- prop_AF_CA_CA_exp_2*RR_CA_exp
    
    # To prevent probabilities > 1 (not needed for deterministic analyses, only occurs in some iterations of the PSA)
    prop_AF_CA_nai        <- ifelse(prop_AF_CA_nai       > 1, 1, prop_AF_CA_nai)       
    prop_AF_CA_AAD_exp    <- ifelse(prop_AF_CA_AAD_exp   > 1, 1, prop_AF_CA_AAD_exp)   
    prop_AF_CA_CA_exp_1   <- ifelse(prop_AF_CA_CA_exp_1  > 1, 1, prop_AF_CA_CA_exp_1)  
    prop_AF_CA_CA_exp_2   <- ifelse(prop_AF_CA_CA_exp_2  > 1, 1, prop_AF_CA_CA_exp_2)  
    prop_AF_AAD_nai       <- ifelse(prop_AF_AAD_nai      > 1, 1, prop_AF_AAD_nai     ) 
    prop_AF_AAD_AAD_exp   <- ifelse(prop_AF_AAD_AAD_exp  > 1, 1, prop_AF_AAD_AAD_exp ) 
    prop_AF_AAD_CA_exp_1  <- ifelse(prop_AF_AAD_CA_exp_1 > 1, 1, prop_AF_AAD_CA_exp_1) 
    prop_AF_AAD_CA_exp_2  <- ifelse(prop_AF_AAD_CA_exp_2 > 1, 1, prop_AF_AAD_CA_exp_2) 
    
    # Convert annual probabilities to cycle length
    p_SFAF_CA_nai          <- 1-convert_probability_to_cl(prop_AF_CA_nai,       1, cl) 
    p_SFAF_CA_AAD_exp      <- 1-convert_probability_to_cl(prop_AF_CA_AAD_exp,   1, cl) 
    p_SFAF_CA_CA_exp_1     <- 1-convert_probability_to_cl(prop_AF_CA_CA_exp_1,  1, cl) 
    p_SFAF_CA_CA_exp_2     <- 1-convert_probability_to_cl(prop_AF_CA_CA_exp_2,  1, cl) 
    p_SFAF_AAD_nai         <- 1-convert_probability_to_cl(prop_AF_AAD_nai,      1, cl) 
    p_SFAF_AAD_AAD_exp     <- 1-convert_probability_to_cl(prop_AF_AAD_AAD_exp,  1, cl) 
    p_SFAF_AAD_CA_exp_1    <- 1-convert_probability_to_cl(prop_AF_AAD_CA_exp_1, 1, cl) 
    p_SFAF_AAD_CA_exp_2    <- 1-convert_probability_to_cl(prop_AF_AAD_CA_exp_2, 1, cl) 
    
    l_inputs_probs_names <- c("RR_AAD_exp", "p_SFAF_CA_nai", "p_SFAF_CA_AAD_exp", "p_SFAF_CA_CA_exp_1", "p_SFAF_CA_CA_exp_2",
                              "p_SFAF_AAD_nai", "p_SFAF_AAD_AAD_exp", "p_SFAF_AAD_CA_exp_1", "p_SFAF_AAD_CA_exp_2")
    l_inputs_probs <- mget(l_inputs_probs_names)
    
    return(l_inputs_probs)
  })
}

```


## 03.3 Probability function

The function that updates the transition probabilities of every cycle is shown below.

```{r}
Probs <- function(l_params_all, M_t, df_X, t) { 
  # Arguments:
  # M_t:   health state occupied by individual i at cycle t (character variable)
  # df_X:  data frame with individual characteristics data 
  # t:     current cycle 
  # Returns: 
  # transition probabilities for that cycle
  
  with((l_params_all),{
    
    # Create matrix of state transition probabilities  
    m_p_t           <- matrix(0, nrow = n_states, ncol = n_i) 
    rownames(m_p_t) <-  v_n  # give the state names to the rows
    
    # Look up probability of dying based on current age
    df_p_D          <- inner_join(df_X, df_mort, by = c("Age", "Sex")) 
    
    # Multiply with HR for excess mortality and cycle length and convert back to probability
    p_D             <- 1 - (1-df_p_D$p_mort_cl)^HR_EM 
    
    # Success rates
    p_SAF_SFAF                                                                <- NULL
    p_SAF_SFAF[df_X$curTrt == "AAD" & df_X$AAD_exp == 0 & df_X$CA_exp_1 == 0] <- p_SFAF_AAD_nai
    p_SAF_SFAF[df_X$curTrt == "AAD" & df_X$AAD_exp == 1 & df_X$CA_exp_1 == 0] <- p_SFAF_AAD_AAD_exp
    p_SAF_SFAF[df_X$curTrt == "AAD" & df_X$AAD_exp == 0 & df_X$CA_exp_1 == 1] <- p_SFAF_AAD_CA_exp_1
    p_SAF_SFAF[df_X$curTrt == "AAD" & df_X$AAD_exp == 1 & df_X$CA_exp_1 == 1] <- p_SFAF_AAD_CA_exp_1
    p_SAF_SFAF[df_X$curTrt == "AAD" & df_X$AAD_exp == 0 & df_X$CA_exp_2 == 1] <- p_SFAF_AAD_CA_exp_2
    p_SAF_SFAF[df_X$curTrt == "AAD" & df_X$AAD_exp == 1 & df_X$CA_exp_2 == 1] <- p_SFAF_AAD_CA_exp_2
    
    p_SAF_SFAF[df_X$curTrt == "CA" & df_X$AAD_exp == 0 & df_X$CA_exp_1 == 0]  <- p_SFAF_CA_nai
    p_SAF_SFAF[df_X$curTrt == "CA" & df_X$AAD_exp == 1 & df_X$CA_exp_1 == 0]  <- p_SFAF_CA_AAD_exp
    p_SAF_SFAF[df_X$curTrt == "CA" & df_X$AAD_exp == 0 & df_X$CA_exp_1 == 1]  <- p_SFAF_CA_CA_exp_1
    p_SAF_SFAF[df_X$curTrt == "CA" & df_X$AAD_exp == 1 & df_X$CA_exp_1 == 1]  <- p_SFAF_CA_CA_exp_1
    p_SAF_SFAF[df_X$curTrt == "CA" & df_X$AAD_exp == 0 & df_X$CA_exp_2 == 1]  <- p_SFAF_CA_CA_exp_2
    p_SAF_SFAF[df_X$curTrt == "CA" & df_X$AAD_exp == 1 & df_X$CA_exp_2 == 1]  <- p_SFAF_CA_CA_exp_2
    p_SAF_SFAF[df_X$curTrt == "no-treatment"]                                 <- 0 # keep symptoms when no rhythm control treatment
    
    # Recurrence rates at time t
    p_SFAF_SAF                                                                 <- NULL
    
    p_SFAF_SAF[df_X$curTrt == "AAD" & df_X$AAD_exp == 0 & df_X$CA_exp_1 == 0]  <- ifelse(p_SFAF_CA_SAF_L1[t]*RR_nai     >1, 1, p_SFAF_CA_SAF_L1[t]*RR_nai    )
    p_SFAF_SAF[df_X$curTrt == "AAD" & df_X$AAD_exp == 1 & df_X$CA_exp_1 == 0]  <- ifelse(p_SFAF_CA_SAF_L1[t]*RR_AAD_exp >1, 1, p_SFAF_CA_SAF_L1[t]*RR_AAD_exp)
    p_SFAF_SAF[df_X$curTrt == "AAD" & df_X$AAD_exp == 0 & df_X$CA_exp_1 == 1]  <- ifelse(p_SFAF_CA_SAF_L2[t]*RR_CA_exp  >1, 1, p_SFAF_CA_SAF_L2[t]*RR_CA_exp )
    p_SFAF_SAF[df_X$curTrt == "AAD" & df_X$AAD_exp == 1 & df_X$CA_exp_1 == 1]  <- ifelse(p_SFAF_CA_SAF_L2[t]*RR_CA_exp  >1, 1, p_SFAF_CA_SAF_L2[t]*RR_CA_exp )
    p_SFAF_SAF[df_X$curTrt == "AAD" & df_X$AAD_exp == 0 & df_X$CA_exp_2 == 1]  <- ifelse(p_SFAF_CA_SAF_L3[t]*RR_CA_exp  >1, 1, p_SFAF_CA_SAF_L3[t]*RR_CA_exp )
    p_SFAF_SAF[df_X$curTrt == "AAD" & df_X$AAD_exp == 1 & df_X$CA_exp_2 == 1]  <- ifelse(p_SFAF_CA_SAF_L3[t]*RR_CA_exp  >1, 1, p_SFAF_CA_SAF_L3[t]*RR_CA_exp )
    
    p_SFAF_SAF[df_X$curTrt == "CA" & df_X$AAD_exp == 0 & df_X$CA_exp_1 == 0]  <- p_SFAF_CA_SAF_L1[t]
    p_SFAF_SAF[df_X$curTrt == "CA" & df_X$AAD_exp == 1 & df_X$CA_exp_1 == 0]  <- p_SFAF_CA_SAF_L1[t]
    p_SFAF_SAF[df_X$curTrt == "CA" & df_X$AAD_exp == 0 & df_X$CA_exp_1 == 1]  <- p_SFAF_CA_SAF_L2[t]
    p_SFAF_SAF[df_X$curTrt == "CA" & df_X$AAD_exp == 1 & df_X$CA_exp_1 == 1]  <- p_SFAF_CA_SAF_L2[t]
    p_SFAF_SAF[df_X$curTrt == "CA" & df_X$AAD_exp == 0 & df_X$CA_exp_2 == 1]  <- p_SFAF_CA_SAF_L3[t]
    p_SFAF_SAF[df_X$curTrt == "CA" & df_X$AAD_exp == 1 & df_X$CA_exp_2 == 1]  <- p_SFAF_CA_SAF_L3[t]

    p_SFAF_SAF[df_X$curTrt == "no-treatment"]                             <- 1-p_D[df_X$curTrt == "no-treatment"] # get symptoms when no rhythm control treatment

    # Fill the transition probability matrix with the appropriate probabilities
    m_p_t[, M_t == "SFAF"]     <- rbind((1-p_SFAF_SAF[M_t == "SFAF"]-p_D[M_t == "SFAF"]),
                                        p_SFAF_SAF[M_t == "SFAF"], 
                                        p_D[M_t == "SFAF"])
    m_p_t[, M_t == "SAF"]      <- rbind(p_SAF_SFAF[M_t == "SAF"], 
                                        1-p_SAF_SFAF[M_t == "SAF"]-p_D[M_t == "SAF"], 
                                        p_D[M_t == "SAF"])
    m_p_t[, M_t == "D"]        <- rbind(0, 0, 1)
    
    if(any(is.na(m_p_t))) {
      warning("NA values found in transition probability matrix")
      print(which(is.na(m_p_t), arr.ind = TRUE))
    }
    
    return(t(m_p_t))
  }) # End of with l_params
}  

```

## 03.4 Prepare costs
```{r}
PrepareCosts <- function(l_params){
  
  with((l_params),{
    
    #### Health state costs #### (Source: Vektis)
    c_before_CA   <- adjust_inflation(c_d_before_CA, "2021")
    c_after_CA    <- adjust_inflation(c_d_after_CA1, "2021") + adjust_inflation(c_d_after_CA2, "2021")
    c_d_SAF       <- adjust_inflation(c_d_SAF, "2021")
    
    #### Intervention costs ####
    # Based on average AAD costs in patients with symptoms of AF (12-6 months before CA)
    c_AAD   <- adjust_inflation(c_AAD, "2021")
    
    # Intervention costs + additional  health care consumption 6 months before and 12 months after CA
    c_CA    <- adjust_inflation(c_CA_DBC, "2021")+c_before_CA+c_after_CA 
    c_CA    <- unname(c_CA)
    
    #### Future medical costs ####
    df_FMC$other_y <- df_FMC$other_y*cl # Adapt to the cycle length
    df_FMC$last_y  <- adjust_inflation(df_FMC$last_y, "2017")
    df_FMC$other_y <- adjust_inflation(df_FMC$other_y, "2017")
    df_FMC         <- as.data.frame(df_FMC)
    
    #### Productivity costs ####
    # Productivity costs consist of three components in this model, recovery time after CA (1 week), work attendance and presenteeism
    
    # Work attendance and presenteeism are estimated with regression models from the EQ-5D-5L to 3L converted health states, age (work attendance) and sex (presenteeism) (Source: Krol et al. 2014). We used the AVATAR-AF data to estimate work attendance and presenteeism for each AF patient in the trial. Then we used a beta-regression to estimate how symptom status influenced work attendance and presenteeism.
    
    # Probability of work attendance based on symptoms. Source: AVATAR-AF and Krol et al. (2014)
    p_SFAF_workattendance <- exp(beta_reg_attendance_intercept)/(1+exp(beta_reg_attendance_intercept))
    p_SAF_workattendance  <- exp((beta_reg_attendance_intercept+beta_reg_attendance_SAF))/
      (1+exp(beta_reg_attendance_intercept+beta_reg_attendance_SAF))
    
    # Proportion at work based on general population corrected for age and sex distribution in AF population
    prop_work             <- (prop_work_M*(1-prop_female)) + prop_work_F*prop_female
    
    # Correct proportion at work for work attendance of AF patients with/without symptoms
    prop_work_SAF         <- prop_work*p_SAF_workattendance # Proportion of patients at work with AF symptoms
    prop_work_SFAF        <- prop_work*p_SFAF_workattendance # Proportion of patients at work without AF symptoms
    
    # Probability of presenteeism (i.e. productivity at work)
    p_SFAF_presenteeism   <- exp(beta_reg_presenteeism_intercept)/(1+exp(beta_reg_presenteeism_intercept))
    p_SAF_presenteeism    <- exp((beta_reg_presenteeism_intercept+beta_reg_presenteeism_SAF))/
      (1+exp(beta_reg_presenteeism_intercept+beta_reg_presenteeism_SAF))
    
    # Productivity costs based on average work duration and wage
    v_hours_per_week      <- v_hours_per_week_F*prop_female+(v_hours_per_week_M*(1-prop_female)) 
    v_hours_per_cycle     <- cl*(365.25/7)*v_hours_per_week # Work hours in a cycle
    c_hourly_wage         <- adjust_inflation(c_hourly_wage_2022, "2022") 
    c_prod_cycle          <- v_hours_per_cycle*c_hourly_wage
    
    # Total productivity: work attendance corrected for presenteeism multiplied with costs
    c_prod_SAF_tot        <- prop_work_SAF*p_SAF_presenteeism*c_prod_cycle # Total productivity costs patients with AF symptoms
    c_prod_SFAF_tot       <- prop_work_SFAF*c_prod_cycle*p_SFAF_presenteeism # Total productivity costs patients without AF symptoms
    c_prod_SAF            <- unname(c_prod_SFAF_tot-c_prod_SAF_tot) # Total productivity costs attributable to having AF symptoms
    
    # Productivity costs of recovery after CA: 1 week absent from work
    c_prod_CA_recovery    <- v_hours_per_week*c_hourly_wage*prop_work_SAF
    
    #### Informal care costs ####
    # Informal care costs are based on a regression model of de Groot et al. (2023) that estimates informal care costs according to age and proximity to death
    # Weighted average life expectancy AF gender distribution, life expectancy is equal to time to death
    T2D              <- (LE_M_77*(1-prop_female))+(LE_F_77*prop_female) 
    
    # Calculate informal care costs for a 77-year old from the general population 
    # Age is centered at the mean in the analysis and 70 is the mean age in de Groot et al. (2023) 
    p_IC_log         <- params_ic_log_intercept + params_ic_log_female*prop_female + params_ic_log_age*(77-70) + 
      params_ic_log_age2*((77-70)*(77-70)) + params_ic_log_T2D*T2D # Propotion use of informal care
    p_IC             <- exp(p_IC_log)/(1+exp(p_IC_log)) # Convert to probability
    v_hr_IC_log      <- params_ic_hours_intercept + params_ic_hours_female*prop_female + params_ic_hours_age*(77-70) + params_ic_hours_T2D*T2D 
    v_hr_day_IC      <- exp(v_hr_IC_log) # Convert from log scale to hours per day
    c_IC_77_cl       <- p_IC*(v_hr_day_IC*365.25*cl)*c_IC_hr # Total costs of informal care in 77-year old in a cycle
    c_IC_77_AF_cl    <- (c_IC_77_AF_2yr/2)*cl # correct for cycle length
    c_IC_SAF         <- c_IC_77_AF_cl-c_IC_77_cl # Informal care costs attributable to symptomatic AF
    
    l_inputs_costs_names <- c("c_d_SAF", "c_AAD", "c_CA", "df_FMC", "c_prod_SAF", "c_prod_CA_recovery", "c_IC_SAF")
    
    l_inputs_costs <- mget(l_inputs_costs_names)
    
    return(l_inputs_costs)
  })
}
```

## 03.5 Cost function

The `Costs` function estimates the costs at every cycle.

```{r}
Costs <- function (l_params_all, M_t, df_X) {
  # M_t: health state occupied by individual i at cycle t (character variable)
  
  with((l_params_all),{
    
    # Objects for future medical costs
    c_FMC   <- inner_join(df_X, df_FMC, by = c("Age", "Sex")) # Look up future medical costs based on current age and sex
    
    # Assign costs based on health states (informal care costs will be added at the end of the MicroSim)
    c_t                                                 <- NULL 

    c_t[M_t == "SFAF" & df_X$curTrt == "AAD"]           <- c_AAD + c_FMC$other_y[M_t == "SFAF" & df_X$curTrt == "AAD"] 
   
    c_t[M_t == "SFAF" & df_X$curTrt == "CA"]            <- c_CA * df_X$TH[M_t == "SFAF" & df_X$curTrt == "CA"] +  
                                                           c_FMC$other_y[M_t == "SFAF" & df_X$curTrt == "CA"] +
                                                          (c_prod_CA_recovery * df_X$TH[M_t == "SFAF" & df_X$curTrt == "CA"]) * 
                                                          (df_X$Age[M_t == "SFAF"  & df_X$curTrt == "CA"]<68)
    
    c_t[M_t == "SFAF" & df_X$curTrt == "no-treatment"]  <- c_FMC$other_y[M_t == "SFAF" & df_X$curTrt == "no-treatment"] 
   
    c_t[M_t == "SAF"  & df_X$curTrt == "AAD"]           <- c_AAD + c_d_SAF + c_FMC$other_y[M_t == "SAF" & df_X$curTrt == "AAD"] +
                                                           c_prod_SAF*(df_X$Age[M_t == "SAF"  & df_X$curTrt == "AAD"]<68) 
    
    c_t[M_t == "SAF"  & df_X$curTrt == "CA"]            <- c_CA + c_d_SAF + c_FMC$other_y[M_t == "SAF" & df_X$curTrt == "CA"] +
                                                           c_prod_SAF*(df_X$Age[M_t == "SAF"  & df_X$curTrt == "CA"]<68) + 
                                                          (c_prod_CA_recovery * df_X$TH[M_t == "SAF" & df_X$curTrt == "CA"]) * 
                                                          (df_X$Age[M_t == "SAF"  & df_X$curTrt == "CA"]<68) 
   
    c_t[M_t == "SAF"  & df_X$curTrt == "no-treatment"]  <- c_d_SAF + c_FMC$other_y[M_t == "SAF" & df_X$curTrt == "no-treatment"] +
                                                           c_prod_SAF*(df_X$Age[M_t == "SAF"  & df_X$curTrt == "no-treatment"]<68) 
    
    c_t[M_t == "D"]                                     <- c_FMC$last_y[M_t == "D"]*df_X$death[M_t == "D"]
    
    return(c_t)        		                      # return the costs
    
  }) # end of with l_params_all
}

```

## 03.6 Health outcome function

The `Effs` function to update the utilities at every cycle.

```{r}
Effs <- function (l_params_all, M_t, df_X, t, cl = cl) {
  # M_t: health state occupied by individual i at cycle t (character variable)
  # df_X: data frame with individual characteristics data 
  
  with((l_params_all),{
    
    # Determine distutilites of adverse events after CA
    du_CT    <- du_CT_mo*cl # Assumption disutility of 0.1 for 1 month, corrected to disutility for the cycle length
    du_PP    <- du_PP_mo*cl # Assumption disutility of 0.1 for 1 month, corrected to disutility for the cycle length
    du_VC    <- du_VC_mo*cl # Assumption disutility of 0.1 for 1 month, corrected to disutility for the cycle length
    
    # Create vector with total disutility per patient based on df_X
    du_AE_CA <- NULL
    du_AE_CA <- (df_X$CT_CA*du_CT)+(df_X$PP_CA*du_PP)+(df_X$VC_CA*du_VC)   
    
    # Determine baseline utility based on general population estimates
    mod_splines$coefficients <- mod_splines_coef # included for use in PSA
    
    if(gen_pop_utility == "fit"){ # For use in base case
      u_t <- unname(predict(mod_splines, newdata = df_X)) 
    }
    
    if(gen_pop_utility == "lwr"){ # For use in OWSA
      u_t <- unname(predict(mod_splines, newdata = df_X, interval = "confidence")[, "lwr"]) 
    }
    
    if(gen_pop_utility == "upr"){ # For use in OWSA
      u_t <- unname(predict(mod_splines, newdata = df_X, interval = "confidence")[, "upr"]) 
    }
    
    # Assign utilities to health states
    u_t[M_t == "SFAF"] <- u_t[M_t == "SFAF"] - du_AE_CA[M_t == "SFAF"] 
    u_t[M_t == "SAF"]  <- u_t[M_t == "SAF"] - du_AE_CA[M_t == "SAF"] - du_SAF 
    u_t[M_t == "D"]    <- 0
    
    QALYs <-  u_t * cl  # calculate the QALYs during cycle t
    
    return(QALYs)       # return the QALYs
    
  }) # end of with l_params_all
}
```

## 03.7 Microsimulation

```{r}

MicroSim <- function(l_params, n_i, df_X, TRT1 = TRT1, TRT2 = TRT2, TRT3 = TRT3, 
                     TRT4 = TRT4, TRT5 = TRT5, TRT6 = TRT6, seed = 1) {
  
  # Arguments:  
  # n_i:     number of individuals
  # df_X     data frame with individual characteristics data 
  # TRT1-3:  The treatments in the sequence
  # seed:    default is 1
  
  #### Set up starting values ####
  df_X        <- Create_df_X(l_params)             # Create dataframe with patient characteristics
  df_X$curTrt <- TRT1                              # Assign the first treatment to all patients
  v_M_init    <- rep("SAF", n_i)                   # All patients start with AF symptoms 
  df_X$TH     <- ifelse(df_X$curTrt == "CA", 1, 0) # If a patient starts on CA, treatment history (TH) is set to 1 
  
  # Calculate input parameters and combine them in l_params_all
  l_inputs_Probs <- PrepareProbs(l_params)
  l_inputs_Costs <- PrepareCosts(l_params)
  l_params_all <- c(l_params, l_inputs_Probs, l_inputs_Costs)
  l_params_all <- l_params_all[!duplicated(names(l_params_all), fromLast = T)]

  with((l_params_all), {
    set.seed(seed) # set the seed
    n_states <- length(v_n) # the number of health states
    
    #### Create matrices ####
    # create matrices with number of rows equal to the n_i, the number of columns equal to n_t  
    # (the initial state and all the n_t cycles)
    # m_M is used to store the health state information over time for every individual
    # m_C is used to store the costs information over time for every individual
    # m_E is used to store the effects information over time for every individual
    # m_L is used to store the line information over time for every individual
    # m_TH is used to store the treatment history of CA over time for every individual
    # m_AE is used to store the adverse events after CA over time for every individual
    # m_D is used to store the death status over time for every individual; used to calculate future medical costs
    # m_C_IC_cl is used to store the informal care costs over time for every individual
    # m_curTrt is used to store the current treatment over time for every individual
    # m_Age is used to store the current age over time for every individual
    
    m_M <- m_C <- m_E <- m_L <- m_TH <- m_AE <- m_D <- m_C_IC_cl <- m_curTrt <- m_Age <- matrix(nrow = n_i, ncol = n_t + 1, 
                                                                                                dimnames = list(paste("ind"  , 1:n_i, sep = " "), 
                                                                                                                paste("cycle", 0:n_t, sep = " ")))  
    
    m_M [, 1]      <- v_M_init    # initial health state at cycle 0 for individual i
    m_TH[, 1]      <- df_X$TH     # initial treatment history at cycle 0 for individual i
    m_L [, 1]      <- rep(1, n_i) # initial line at cycle 0 for individual i
    m_D [, 1]      <- df_X$death  # initial death status at cycle 0 for individual i
    m_C_IC_cl[, 1] <- rep(0, n_i) # initial costs of informal care
    m_curTrt[, 1]  <- df_X$curTrt # initial treatment
    m_Age[, 1]     <- df_X$Age    # initial age

    #### Cycle 0 ####
    # Costs and QALYs in cycle 1
    m_C[, 1]  <- Costs(l_params_all, m_M[, 1], df_X)     
    m_E[, 1]  <- Effs (l_params_all, m_M[, 1], df_X, t = 1, cl = cl) 
    
    #### Start loop cycle 1 to n_t ####
    # Open a loop for time running cycles 1 to n_t 
    for (t in 1:n_t) {
      
      # To remove variability due to random draw procedure (seed) but keep variation between cycles (+ t)
      set.seed(seed + t)
      
      #### Switch health states ####
      # Calculate the transition probabilities for the cycle based on  health state t
      m_P <- Probs(l_params_all, m_M[, t], df_X, t)             
      
      # Sample the current health state based on the transition probabilities and store that state in matrix m_M 
      m_M[, t + 1]  <- samplev(m_P, 1)   
      
      #### Adverse events ####
      # Discontinue AAD due to adverse events
      df_X$disc_AAD[df_X$curTrt == "AAD" & df_X$AAD_exp == 0] <- rbinom(sum(df_X$curTrt == "AAD" & df_X$AAD_exp == 0), 1, p_disc_AAD_nai)
      df_X$disc_AAD[df_X$curTrt == "AAD" & df_X$AAD_exp == 1] <- rbinom(sum(df_X$curTrt == "AAD" & df_X$AAD_exp == 1), 1, p_disc_AAD_exp)
      
      # Adverse events during the first cycle after CA 
      df_X$PP_CA[df_X$curTrt == "CA" & df_X$TH == 1] <- rbinom(sum(df_X$curTrt == "CA" & df_X$TH == 1), 1, p_PP_CA)
      df_X$CT_CA[df_X$curTrt == "CA" & df_X$TH == 1] <- rbinom(sum(df_X$curTrt == "CA" & df_X$TH == 1), 1, p_CT_CA)
      df_X$VC_CA[df_X$curTrt == "CA" & df_X$TH == 1] <- rbinom(sum(df_X$curTrt == "CA" & df_X$TH == 1), 1, p_VC_CA)
      
      m_AE[, t+ 1] <- df_X$PP_CA + df_X$CT_CA +df_X$VC_CA 
      
      #### Switching lines ####
      # Switch lines when symptoms of AF or discontinuation of AAD
      # If maximum number of lines has been reached, switch to no rhythm control treatment
      df_X$Line[m_M[ , t + 1] == "SFAF" & df_X$disc_AAD == 0]                   <- df_X$Line[m_M[ , t + 1] == "SFAF" & df_X$disc_AAD == 0] 
      df_X$Line[m_M[ , t + 1] == "SFAF" & df_X$disc_AAD == 1 & df_X$Line >= 6]  <- 555 # no rhythm control treatment 
      df_X$Line[m_M[ , t + 1] == "SFAF" & df_X$disc_AAD == 1 & df_X$Line < 6]   <- df_X$Line[m_M[ , t + 1] == "SFAF"& df_X$disc_AAD == 1 & df_X$Line < 6] + 1  
      df_X$Line[m_M[ , t + 1] == "SAF" & df_X$Line >= 6]                        <- 555 # no rhythm control treatment
      df_X$Line[m_M[ , t + 1] == "SAF" & df_X$Line < 6]                         <- df_X$Line[m_M[ , t + 1] == "SAF" & df_X$Line < 6] + 1
      df_X$Line[m_M[ , t + 1] == "D"]                                           <- 999 # dead
      
      # Update matrix with current line number
      m_L[ , t + 1] <- df_X$Line
      
      # Update current treatment for the next cycle
      df_X$curTrt[df_X$Line == 1]   <- TRT1
      df_X$curTrt[df_X$Line == 2]   <- TRT2
      df_X$curTrt[df_X$Line == 3]   <- TRT3
      df_X$curTrt[df_X$Line == 4]   <- TRT4
      df_X$curTrt[df_X$Line == 5]   <- TRT5
      df_X$curTrt[df_X$Line == 6]   <- TRT6
      df_X$curTrt[df_X$Line == 555] <- "no-treatment"
      df_X$curTrt[df_X$Line == 999] <- "D"
      
      m_curTrt[, t + 1]  <- df_X$curTrt
      
      # Update the evaluation of first month of ablation
      df_X$TH       <- ifelse(df_X$curTrt == "CA" & m_L[,t] != m_L[,t+1], 1, 0)
      m_TH[, t + 1] <- df_X$TH
      
      # Update variables for AAD or CA exposure
      # Exposed to AAD
      df_X$AAD_exp[TRT1 == "AAD" & df_X$Line > 1] <- 1
      df_X$AAD_exp[TRT2 == "AAD" & df_X$Line > 2] <- 1
      df_X$AAD_exp[TRT3 == "AAD" & df_X$Line > 3] <- 1
      df_X$AAD_exp[TRT4 == "AAD" & df_X$Line > 4] <- 1
      df_X$AAD_exp[TRT5 == "AAD" & df_X$Line > 5] <- 1

      # Exposed to CA at least once
      df_X$CA_exp_1[TRT1 == "CA" & df_X$Line > 1]   <- 1
      df_X$CA_exp_1[TRT2 == "CA" & df_X$Line > 2]   <- 1
      df_X$CA_exp_1[TRT3 == "CA" & df_X$Line > 3]   <- 1
      df_X$CA_exp_1[TRT4 == "CA" & df_X$Line > 4]   <- 1
      df_X$CA_exp_1[TRT5 == "CA" & df_X$Line > 5]   <- 1

      # Exposed to CA at least twice
      df_X$CA_exp_2[TRT1 == "CA" & TRT2 == "CA" & df_X$Line > 2] <- 1
      df_X$CA_exp_2[TRT1 == "CA" & TRT3 == "CA" & df_X$Line > 3] <- 1
      df_X$CA_exp_2[TRT1 == "CA" & TRT4 == "CA" & df_X$Line > 4] <- 1
      df_X$CA_exp_2[TRT1 == "CA" & TRT5 == "CA" & df_X$Line > 5] <- 1
      df_X$CA_exp_2[TRT2 == "CA" & TRT3 == "CA" & df_X$Line > 3] <- 1
      df_X$CA_exp_2[TRT2 == "CA" & TRT4 == "CA" & df_X$Line > 4] <- 1
      df_X$CA_exp_2[TRT2 == "CA" & TRT5 == "CA" & df_X$Line > 5] <- 1
      df_X$CA_exp_2[TRT3 == "CA" & TRT4 == "CA" & df_X$Line > 4] <- 1
      df_X$CA_exp_2[TRT3 == "CA" & TRT5 == "CA" & df_X$Line > 5] <- 1
      df_X$CA_exp_2[TRT4 == "CA" & TRT5 == "CA" & df_X$Line > 5] <- 1

      # Set adverse events status back to zero for everyone 
      df_X$disc_AAD <- df_X$CT_CA <- df_X$PP_CA <- df_X$VC_CA <- 0 
      
      # Update the age of individuals that are alive
      df_X$Age_cl[m_M[, t + 1] != "D"]  <- df_X$Age_cl[m_M[, t + 1] != "D"] + cl
      df_X$Age[m_M[, t + 1] != "D"]     <- round_age(df_X$Age_cl[m_M[, t + 1] != "D"]) # rounded for use with background mortality and FMC
      
      m_Age[, t + 1] <- df_X$Age
      
      # Update death status in m_D and in df_X to capture the costs of last year of life in the Costs function
      m_D[, t + 1] <- ifelse(m_M[, t + 1] == "D" , 1, 0)
      df_X$death <- ifelse(m_D[, t] == 0 & m_D[, t + 1] == 1, 1, 0) # i.e. only 1 if not dead in previous cycle
      
      #### Calculate costs and QALYs ####
      # Calculate costs per individual during cycle t + 1
      m_C[, t + 1]  <- Costs(l_params_all, m_M[, t + 1], df_X)         
      
      # Calculate QALYs per individual during cycle t + 1
      m_E[, t + 1]  <- Effs(l_params_all, m_M[, t + 1], df_X, t, cl = cl) 
      
      # Display simulation progress
      if(t/(n_t/10) == round(t/(n_t/10), 0)) { # display progress every 10%
        cat('\r', paste(t/n_t * 100, "% done", sep = " "))
      }
      
    } # close the loop for the time points 
    
    #### Calculate informal care costs based on T2D ####
    # Calculate the time to death per individual
    T2D_data_temp    <- ifelse(m_M == "D", 0, 1) # Replace all 'A' for 1 and all 'D' for 0
    T2D_data         <- unname(rowSums(T2D_data_temp)*cl) # Calculate the sums of every row i.e. the time to death per individual, expressed in years
    m_C_IC_a         <- matrix(nrow = n_i, ncol = (n_t + 1)*cl)
    m_C_IC_a[, 1]    <- rep(0, n_i) # Matrix to capture informal care costs with time to death
    
    # Start loop over patients
    for(i in 1:n_i){ 
      T2D <- T2D_data[i] # determine time to death of individual i
      # Start loop over time to death for individual i
      for(t in 1:T2D){ # loop over start simulation until death of individual i
        
        # Calculate informal care costs for individual i at time t
        p_care_use    <- l_params$params_ic_log_intercept + l_params$params_ic_log_female*df_X$Sex[i] +
          l_params$params_ic_log_age*((df_X$Age_start[i]+t)-70) + 
          l_params$params_ic_log_age2*(((df_X$Age_start[i]+t)-70)*((df_X$Age_start[i]+t)-70)) + l_params$params_ic_log_T2D*(T2D-t)
        v_hour_care   <- l_params$params_ic_hours_intercept + l_params$params_ic_hours_female*df_X$Sex[i] +
          l_params$params_ic_hours_age*((df_X$Age_start[i]+t)-70) + l_params$params_ic_hours_T2D*(T2D-t) #estimates hours per day
        m_C_IC_a[i,t] <- (exp(p_care_use)/(1+exp(p_care_use)))*exp(v_hour_care)*c_IC_hr*365.25  # matrix with annual costs
      }
    }
    
    # Adjust the caregiver costs annual matrix to  cycle length
    for (h in 1:((n_t + 1)*cl)) {
      # Each original column value is split evenly between two new columns
      m_C_IC_cl[, 2*h-1] <- m_C_IC_a[, h]*cl
      m_C_IC_cl[, 2*h]   <- m_C_IC_a[, h]*cl
    }
    
    # Adjust the caregiver matrix for those with and without symptoms
    m_C_IC_cl[m_M == "SAF"] <- m_C_IC_cl[m_M == "SAF"] + c_IC_SAF # Add the AF specific caregiver burden costs
    
    #### Calculate and discount lifetime costs and effects ####
    m_C_IC_cl             <- ifelse(is.na(m_C_IC_cl), 0, m_C_IC_cl) # replace NAs with zero in the cycles where patients are dead
    m_C                   <- m_C + m_C_IC_cl                        # combine regular costs with informal care costs
    m_LY                  <- ifelse(m_M=="D", 0, cl)                # undiscounted life years (i.e. not corrected for quality of life)
    
    tc                    <- m_C %*% (v_dwc * v_wcc)  # total discounted cost per individual
    te                    <- m_E %*% (v_dwe * v_wcc)  # total discounted QALYs per individual 
    tLY                   <- m_LY %*% (v_dwe * v_wcc) # total discounted LYs per individual 
    tLY_undisc            <- m_LY %*% (v_wcc)         # total undiscounted LYs per individual 
    
    tc_hat                <- mean(tc)                 # average discounted cost 
    te_hat                <- mean(te)                 # average discounted QALYs
    tLY_hat               <- mean(tLY)                # average disounted LYs
    tLY_undisc_hat        <- mean(tLY_undisc)         # average undisounted LYs
    
    
    #### Store the results from the simulation in a list ####
    if(PSA == F){
      
      # Determine time on treatment in each line
      m_ToT             <- m_L 
      m_ToT[m_M == "D"] <- NA # if you are dead, remove treatment line
      m_ToT             <- m_ToT[,-1] # remove cycle 0
      
      # Determine proportion on treatment line
      df_PoT <- data.frame(p_L1 = rep(0, n_i),
                           p_L2 = rep(0, n_i),
                           p_L3 = rep(0, n_i),
                           p_L4 = rep(0, n_i),
                           p_L5 = rep(0, n_i),
                           p_L6 = rep(0, n_i), 
                           p_noTrt = rep(0, n_i))
      
      df_PoT[ , 1] <- as.numeric(ifelse(rowSums(m_ToT=="1", na.rm = T)==0, NA, rowSums(m_ToT=="1", na.rm = T)))  
      df_PoT[ , 2] <- as.numeric(ifelse(rowSums(m_ToT=="2", na.rm = T)==0, NA, rowSums(m_ToT=="2", na.rm = T)))
      df_PoT[ , 3] <- as.numeric(ifelse(rowSums(m_ToT=="3", na.rm = T)==0, NA, rowSums(m_ToT=="3", na.rm = T)))
      df_PoT[ , 4] <- as.numeric(ifelse(rowSums(m_ToT=="4", na.rm = T)==0, NA, rowSums(m_ToT=="4", na.rm = T)))
      df_PoT[ , 5] <- as.numeric(ifelse(rowSums(m_ToT=="5", na.rm = T)==0, NA, rowSums(m_ToT=="5", na.rm = T)))
      df_PoT[ , 6] <- as.numeric(ifelse(rowSums(m_ToT=="6", na.rm = T)==0, NA, rowSums(m_ToT=="6", na.rm = T)))
      df_PoT[ , 7] <- as.numeric(ifelse(rowSums(m_ToT=="555", na.rm = T)==0, NA, rowSums(m_ToT=="555", na.rm = T)))
      
      t_L1    <- mean(df_PoT[, 1], na.rm = T)*cl 
      t_L2    <- mean(df_PoT[, 2], na.rm = T)*cl 
      t_L3    <- mean(df_PoT[, 3], na.rm = T)*cl 
      t_L4    <- mean(df_PoT[, 4], na.rm = T)*cl 
      t_L5    <- mean(df_PoT[, 5], na.rm = T)*cl 
      t_L6    <- mean(df_PoT[, 6], na.rm = T)*cl 
      t_noTrt <- mean(df_PoT[, 7], na.rm = T)*cl 
      
      # Proportion receiving treatment
      p_L1    <- 100 #everybody starts on line 1
      p_L2    <- (sum(!is.na(df_PoT[, 2]))/n_i)*100
      p_L3    <- (sum(!is.na(df_PoT[, 3]))/n_i)*100
      p_L4    <- (sum(!is.na(df_PoT[, 4]))/n_i)*100
      p_L5    <- (sum(!is.na(df_PoT[, 5]))/n_i)*100
      p_L6    <- (sum(!is.na(df_PoT[, 6]))/n_i)*100
      p_noTrt <- (sum(!is.na(df_PoT[, 7]))/n_i)*100
      
      results <- list(m_M = m_M, m_C = m_C, m_E = m_E, m_L = m_L, 
                      m_ToT = m_ToT, m_TH = m_TH, m_AE = m_AE, m_C_IC_cl = m_C_IC_cl,
                      m_C_IC_a = m_C_IC_a,T2D_data = T2D_data,T2D_data_temp = T2D_data_temp, m_curTrt = m_curTrt, m_D = m_D, m_Age = m_Age,
                      tc = tc, te = te, tLY = tLY, tLY_undisc = tLY_undisc, 
                      tc_hat = tc_hat, te_hat = te_hat, tLY_hat = tLY_hat, tLY_undisc_hat = tLY_undisc_hat, 
                      p_L1 = p_L1, p_L2 = p_L2, p_L3 = p_L3, p_L4 = p_L4, p_L5 = p_L5, p_L6 = p_L6, p_noTrt = p_noTrt, 
                      t_L1= t_L1, t_L2 = t_L2, t_L3 = t_L3, t_L4 = t_L4,  t_L5 = t_L5, t_L6 = t_L6, t_noTrt = t_noTrt)
    }
    
    if(PSA == T){
      results <- list(m_M = m_M, m_C = m_C, m_E = m_E, tc = tc , te = te, tc_hat = tc_hat, te_hat = te_hat, tLY_hat = tLY_hat, tLY_undisc_hat = tLY_undisc_hat)
    }
    
    if(mainresults == T){
      results <- list(tc_hat = tc_hat, te_hat = te_hat)
    }
    
    return(results)  # return the results
  }) # end of with(l_params)
  
} # end of the MicroSim function  
```

# 04 Run the simulation 
First run all previous sections

## 04.1 Single sequence

```{r}
# Variables that can be set to T to return less results to decrease runtime
PSA         <- F
mainresults <- F 

# Identify the desired sequence using TRT1 to TRT6. Treatment options are catheter ablation "CA" or anti-arrhythmic drugs "AAD".
outcomes <- MicroSim(l_params, n_i, df_X, TRT1 = "AAD", TRT2 = "CA", TRT3 = "AAD", TRT4 = "AAD", TRT5 = "AAD", TRT6 = "CA", seed = 1)

outcomes$te_hat         # Mean lifetime discounted QALYs
outcomes$tc_hat         # Mean lifetime discounted costs

# # Check if everyone died at the end of the simulation (should be equal to n_i)
# table(outcomes$m_M[,n_t+1])
# 
# Plot health state and line membership over time
plot_m_TR(outcomes$m_M)
plot_trace_line(outcomes$m_L)


```

## 04.2 All sequences
```{r}
# Define treatment sequences (the model has a maximum of 6 treatment lines)
# Not all patients that enter the model will receive all 6 treatment lines, only those with AF recurrence move to the next line
df_trtseq <- expand.grid(line1 = c("AAD", "CA"), 
                         line2 = c("AAD", "CA"),
                         line3 = c("AAD", "CA"),
                         line4 = c("AAD", "CA"),
                         line5 = c("AAD", "CA"),
                         line6 = c("AAD", "CA"), stringsAsFactors = FALSE)

v_names_str <- c(paste(df_trtseq$line1, df_trtseq$line2, df_trtseq$line3,
                       df_trtseq$line4, df_trtseq$line5, df_trtseq$line6, sep="-"))

# Variables that can be set to T to return less results to decrease runtime
PSA         <- F
mainresults <- F 

# Setup parallel processing to reduce runtime
num_cores          <- detectCores() - 1  # Leave one core free for system processes
cluster            <- makeCluster(num_cores)
registerDoParallel(cluster)

# Export necessary objects to the cluster
clusterExport(cluster, c('MicroSim', 'Create_df_X', 'n_i', 'rtruncnorm', 'v_n', 'n_states',
                         'n_t',  'Costs', 'Effs', 'Probs', 'PrepareProbs', 'PrepareCosts', 
                         'cl', 'v_dwc', 'v_dwe', 'v_wcc', 'min_age', 'max_age', 'PSA',
                         'df_mort', 'beta_reg_attendance', 'beta_reg_presenteeism', 'params_ic_log', 'params_ic_hours', 'mod_splines'))

# Export necessary packages to the cluster
clusterEvalQ(cluster, 
             {library(dplyr) 
               library(darthtools)
               library(splines)
               source(here::here("functions", "functions.R"))
             })

tic()
results <- foreach(g = 1:nrow(df_trtseq), 
                   .packages = c("darthtools")) %dopar% { # darthtools voor sample v
                     MicroSim(l_params, n_i, df_X, TRT1 = df_trtseq[g,1], TRT2 = df_trtseq[g,2], 
                              TRT3 = df_trtseq[g,3], TRT4 = df_trtseq[g,4], TRT5 = df_trtseq[g,5], 
                              TRT6 = df_trtseq[g,6], seed = 1)
                   }
toc()
stopCluster(cluster)

# Store the mean costs, LYs, QALYs, and clinical outcomes of each strategy in new variables
v_C <- v_E <- tLY_hat <- tLY_undisc_hat <- p_L1 <- p_L2 <- p_L3 <- p_L4 <- p_L5 <- p_L6 <- p_noTrt <- 
  t_L1 <- t_L2 <- t_L3 <- t_L4 <- t_L5 <- t_L6 <- t_noTrt  <- NULL

for (i in 1:length(results)){
  v_C[i]               <- results[[i]]$tc_hat
  v_E[i]               <- results[[i]]$te_hat
  tLY_hat[i]           <- results[[i]]$tLY_hat
  tLY_undisc_hat[i]    <- results[[i]]$tLY_undisc_hat
  t_L1[i]              <- results[[i]]$t_L1   
  t_L2[i]              <- results[[i]]$t_L2   
  t_L3[i]              <- results[[i]]$t_L3   
  t_L4[i]              <- results[[i]]$t_L4  
  t_L5[i]              <- results[[i]]$t_L5  
  t_L6[i]              <- results[[i]]$t_L6  
  t_noTrt[i]           <- results[[i]]$t_noTrt
  p_L1[i]              <- results[[i]]$p_L1   
  p_L2[i]              <- results[[i]]$p_L2   
  p_L3[i]              <- results[[i]]$p_L3  
  p_L4[i]              <- results[[i]]$p_L4   
  p_L5[i]              <- results[[i]]$p_L5   
  p_L6[i]              <- results[[i]]$p_L6  
  p_noTrt[i]           <- results[[i]]$p_noTrt
}

# Combine the results in a data frame (without calculate_icers)
results_ce <- data.frame(Treatment_sequence = v_names_str,
                         Cost               = v_C,
                         QALYs              = v_E,
                         LYs                = tLY_hat,
                         LYs_undiscounted   = tLY_undisc_hat,
                         NHB                = v_E-(v_C/wtp),
                         Time_in_line1      = t_L1,
                         Time_in_line2      = t_L2,
                         Time_in_line3      = t_L3,
                         Time_in_line4      = t_L4,
                         Time_in_line5      = t_L5,
                         Time_in_line6      = t_L6,
                         Time_discontinued  = t_noTrt,
                         Prop_in_line1      = p_L1,
                         Prop_in_line2      = p_L2, 
                         Prop_in_line3      = p_L3,
                         Prop_in_line4      = p_L4,
                         Prop_in_line5      = p_L5, 
                         Prop_in_line6      = p_L6, 
                         Prop_discontinued  = p_noTrt
)

results_ce <- cbind(results_ce[, 1], separate(results_ce, col = "Treatment_sequence", c("L1","L2","L3", "L4", "L5", "L6"), "-"))
colnames(results_ce)[colnames(results_ce) == 'results_ce[, 1]'] <- 'Treatment_sequence'

# Save results
write.csv(results_ce, here::here("output", "results_scenario_ni50000.csv"))

```

## 04.3 Make sense of the results
### Base-case analysis
```{r}
results_ce <- read.csv(here::here("output", "results_bc_ni50000.csv")) 

# Define reference treatment sequence
reference_sequence <- "AAD-AAD-AAD-AAD-AAD-AAD"

# Get reference values
reference_values <- results_ce[results_ce$Treatment_sequence == reference_sequence, ]
reference_qalys  <- reference_values$QALYs
reference_cost   <- reference_values$Cost

# Calculate incremental values and iNHB
wtp <- 20000
results_ce$inc_QALYs_vsAAD <- results_ce$QALYs - reference_qalys
results_ce$inc_Cost_vsAAD  <- results_ce$Cost - reference_cost
results_ce$iNHB_vsAAD      <- results_ce$inc_QALYs_vsAAD - (results_ce$inc_Cost_vsAAD / wtp)
results_ce$ICER_vsAAD      <- ifelse(results_ce$inc_QALYs_vsAAD > 0 & results_ce$inc_Cost_vsAAD < 0, NA, results_ce$inc_Cost_vsAAD/results_ce$inc_QALYs_vsAAD)

# Add a counter for number of CA's in a sequence
results_ce$n_ca <- apply(results_ce[, c("L1", "L2", "L3", "L4", "L5", "L6")], 1, 
                      function(x) sum(x == "CA"))
results_ce$ca_first <- ifelse(results_ce[, c("L1")] == "CA", 1, 0)

# View(results_ce)        
              
# Fully incremental analysis
icers_ce   <- calculate_icers(cost       = results_ce$Cost,
                              effect     = results_ce$QALYs,
                              strategies = results_ce$Treatment_sequence)
icers_ce

# Export results to Microsoft Word
 library(flextable)
 library(officer)

results_ce_report1 <- results_ce %>%
  dplyr::select(Treatment_sequence, Cost, QALYs, LYs, inc_Cost_vsAAD, inc_QALYs_vsAAD, iNHB_vsAAD) %>% 
  arrange(desc(iNHB_vsAAD))

results_ce_report2 <- results_ce %>%
  dplyr::select(Treatment_sequence, Time_in_line1:Prop_discontinued, iNHB_vsAAD) %>% 
  arrange(desc(iNHB_vsAAD))

# Create a flextable object
ft <- flextable(results_ce_report1)

# Customize the table (optional)
ft <- autofit(ft)  # Automatically adjust column widths
#ft <- theme_vanilla(ft)  # Apply a theme

ft <- colformat_double(ft, j = "Cost", digits = 0, big.mark = ",")   
ft <- colformat_double(ft, j = "QALYs", digits = 3)  
ft <- colformat_double(ft, j = "LYs", digits = 3)   
ft <- colformat_double(ft, j = "inc_QALYs_vsAAD", digits = 3)  
ft <- colformat_double(ft, j = "inc_Cost_vsAAD", digits = 0, big.mark = ",")   
ft <- colformat_double(ft, j = "iNHB_vsAAD", digits = 3) 

# Save to Word document
doc <- read_docx()  # Create a new Word document
doc <- body_add_flextable(doc, value = ft)  # Add the table to the document
print(doc, target = here::here("output", "iNHBranking_bc.docx"))  # Save the document

ft <- flextable(results_ce_report2)

# Customize the table (optional)
ft <- autofit(ft)  # Automatically adjust column widths
#ft <- theme_vanilla(ft)  # Apply a theme
ft <- colformat_double(ft, j = "Time_in_line1", digits = 1) 
ft <- colformat_double(ft, j = "Time_in_line2", digits = 1) 
ft <- colformat_double(ft, j = "Time_in_line3", digits = 1) 
ft <- colformat_double(ft, j = "Time_in_line4", digits = 1) 
ft <- colformat_double(ft, j = "Time_in_line5", digits = 1) 
ft <- colformat_double(ft, j = "Time_in_line6", digits = 1) 
ft <- colformat_double(ft, j = "Time_discontinued", digits = 1) 
ft <- colformat_double(ft, j = "Prop_in_line1", digits = 1) 
ft <- colformat_double(ft, j = "Prop_in_line2", digits = 1) 
ft <- colformat_double(ft, j = "Prop_in_line3", digits = 1) 
ft <- colformat_double(ft, j = "Prop_in_line4", digits = 1) 
ft <- colformat_double(ft, j = "Prop_in_line5", digits = 1) 
ft <- colformat_double(ft, j = "Prop_in_line6", digits = 1) 
ft <- colformat_double(ft, j = "Prop_discontinued", digits = 1) 

# Save to Word document
doc <- read_docx()  # Create a new Word document
doc <- body_add_flextable(doc, value = ft)  # Add the table to the document
print(doc, target = here::here("output", "Time_prop_lines_bc.docx"))  # Save the document
```

Means by first line CA and first line AAD
```{r}
# Means by first line CA and first line AAD
results_ce %>%
  group_by(ca_first) %>%
    summarize(
      count = n(),
      mean_costs = mean(Cost),
      mean_QALYs = mean(QALYs),
      mean_lifetimeSFAF_L1 = 100-mean(Prop_in_line2),
      mean_timeL1 = mean(Time_in_line1),
  # other summary statistics...
)
```

### Scenario analysis
```{r}
results_ce_scenario <- read.csv(here::here("output", "results_scenario_ni50000.csv"))

# Get reference values
reference_values <- results_ce_scenario[results_ce_scenario$Treatment_sequence == reference_sequence, ]
reference_qalys  <- reference_values$QALYs
reference_cost   <- reference_values$Cost

# Calculate incremental values and iNHB
results_ce_scenario$inc_QALYs_vsAAD <- results_ce_scenario$QALYs - reference_qalys
results_ce_scenario$inc_Cost_vsAAD  <- results_ce_scenario$Cost - reference_cost
results_ce_scenario$iNHB_vsAAD      <- results_ce_scenario$inc_QALYs_vsAAD - (results_ce_scenario$inc_Cost_vsAAD / wtp)
results_ce_scenario$ICER_vsAAD      <- ifelse(results_ce_scenario$inc_QALYs_vsAAD > 0 & results_ce_scenario$inc_Cost_vsAAD < 0, NA, results_ce_scenario$inc_Cost_vsAAD/results_ce_scenario$inc_QALYs_vsAAD)

# Add a counter for number of CA's in a sequence
results_ce_scenario$n_ca <- apply(results_ce_scenario[, c("L1", "L2", "L3", "L4", "L5", "L6")], 1, 
                      function(x) sum(x == "CA"))
results_ce_scenario$ca_first <- ifelse(results_ce_scenario[, c("L1")] == "CA", 1, 0)

# View(results_ce_scenario)

#fully incremental
icers_ce_scenario         <-    calculate_icers(cost       = results_ce_scenario$Cost,
                                       effect     = results_ce_scenario$QALYs,
                                       strategies = results_ce_scenario$Treatment_sequence)
icers_ce_scenario
 
```

### Combine basecase and scenario results
```{r}
# Add ranking numbers to the scenario analysis to compare with ranking of base case analysis
results_ce_scenario <- results_ce_scenario %>%   
  mutate(rank_sc = rank(desc(iNHB_vsAAD), ties.method = "min"))

# Comparison of base case and scenario analysis results
results_bc <- results_ce %>%
  dplyr::select(Treatment_sequence, Cost, QALYs, iNHB_vsAAD)

results_scenario <- results_ce_scenario %>%
  dplyr::select(Treatment_sequence, Cost, QALYs, iNHB_vsAAD, rank_sc)

joined_results <- inner_join(  
  # Add prefix to columns from results_bc  
  rename_with(results_bc, ~paste0("bc_", .), .cols = -Treatment_sequence), 
  # Add prefix to columns from results_scenario  
  rename_with(results_scenario, ~paste0("sc_", .), .cols = -Treatment_sequence),  
  # Join by Treatment_sequence
  by = "Treatment_sequence")

View(joined_results)

# Export results to Microsoft Word
 library(flextable)
 library(officer)

joined_results <- joined_results %>%
  arrange(desc(bc_iNHB_vsAAD))

# Create a flextable object
ft <- flextable(joined_results)

# Customize the table (optional)
ft <- autofit(ft)  # Automatically adjust column widths
#ft <- theme_vanilla(ft)  # Apply a theme

ft <- colformat_double(ft, j = "bc_Cost", digits = 0, big.mark = ",")   
ft <- colformat_double(ft, j = "bc_QALYs", digits = 3)   
ft <- colformat_double(ft, j = "bc_iNHB_vsAAD", digits = 3) 
ft <- colformat_double(ft, j = "sc_Cost", digits = 0, big.mark = ",")   
ft <- colformat_double(ft, j = "sc_QALYs", digits = 3)   
ft <- colformat_double(ft, j = "sc_iNHB_vsAAD", digits = 3) 

# Save to Word document
doc <- read_docx()  # Create a new Word document
doc <- body_add_flextable(doc, value = ft)  # Add the table to the document
print(doc, target = here::here("output", "iNHBranking_bc_sc.docx"))  # Save the document

```

# 05 OWSA
## 05.1 Define input parameters
```{r}
## Define two sequences for which you want to run the OWSA
# CA-AAD-AAD-AAD-AAD-CA
TRT1a <- "CA"
TRT2a <- "AAD"
TRT3a <- "AAD"
TRT4a <- "AAD"
TRT5a <- "AAD"
TRT6a <- "CA"

# CA-AAD-AAD-AAD-CA-CA
TRT1b <- "CA"
TRT2b <- "AAD"
TRT3b <- "AAD"
TRT4b <- "AAD"
TRT5b <- "CA"
TRT6b <- "CA"

l_params_owsa <- l_params_owsa_min <- l_params_owsa_max <- l_params 

# Proportion with which you vary the base case settings
lower <- 0.8
upper <- 1.2

# Patient characteristics: confidence intervals derived from Mol et al. 2022 using normal and beta distributions
l_params_owsa_min$age                      <- age
l_params_owsa_max$age                      <- age
l_params_owsa_min$sd_age                   <- sd_age
l_params_owsa_max$sd_age                   <- sd_age
owsa_min_age                               <- age - qnorm(0.975) * (sd_age/sqrt(n_total))
owsa_max_age                               <- age + qnorm(0.975) * (sd_age/sqrt(n_total))
l_params_owsa_min$v_age                    <- round(rtruncnorm(n_i, min_age, max_age, owsa_min_age, sd_age)) 
l_params_owsa_max$v_age                    <- round(rtruncnorm(n_i, min_age, max_age, owsa_max_age, sd_age)) 

l_params_owsa_min$prop_female              <- prop_female
l_params_owsa_max$prop_female              <- prop_female
owsa_min_prop_female                       <- qbeta(0.025, n_female, n_male)
owsa_max_prop_female                       <- qbeta(0.975, n_female, n_male)
l_params_owsa_min$v_Sex                    <- rbinom(n_i, 1, owsa_min_prop_female)
l_params_owsa_max$v_Sex                    <- rbinom(n_i, 1, owsa_max_prop_female)

l_params_owsa_min$prop_parox               <- qbeta(0.025, n_paroxysmal, n_persistent)
l_params_owsa_max$prop_parox               <- qbeta(0.975, n_paroxysmal, n_persistent)

# Clinical input parameters 
# Confidence intervals as reported by Cochrane Netherlands
l_params_owsa_min$RR_nai                   <- unname(exp(predrema1$ci.lb)) 
l_params_owsa_max$RR_nai                   <- unname(exp(predrema1$ci.ub))
l_params_owsa_min$RR_AAD_exp_parox         <- unname(exp(predrema2$ci.lb)) 
l_params_owsa_max$RR_AAD_exp_parox         <- unname(exp(predrema2$ci.ub))
l_params_owsa_min$RR_AAD_exp_pers          <- unname(exp(predrema3$ci.lb)) 
l_params_owsa_max$RR_AAD_exp_pers          <- unname(exp(predrema3$ci.ub))
l_params_owsa_min$RR_CA_exp                <- 1.61 # based on 1 study
l_params_owsa_max$RR_CA_exp                <- 2.80 # based on 1 study
l_params_owsa_min$prop_AF_CA_nai           <- unname(plogis(predrema1i$ci.lb))
l_params_owsa_max$prop_AF_CA_nai           <- unname(plogis(predrema1i$ci.ub)) 
l_params_owsa_min$prop_AF_CA_AAD_exp_parox <- unname(plogis(predrema2i$ci.lb))
l_params_owsa_max$prop_AF_CA_AAD_exp_parox <- unname(plogis(predrema2i$ci.ub))
l_params_owsa_min$prop_AF_CA_AAD_exp_pers  <- unname(plogis(predrema3i$ci.lb))
l_params_owsa_max$prop_AF_CA_AAD_exp_pers  <- unname(plogis(predrema3i$ci.ub))
l_params_owsa_min$p_disc_AAD_nai           <- 0.067
l_params_owsa_max$p_disc_AAD_nai           <- 0.206
l_params_owsa_min$p_disc_AAD_exp           <- 0.161
l_params_owsa_max$p_disc_AAD_exp           <- 0.305

# Confidence intervals derived from survival curve of Vektis data
l_params_owsa_min$prop_AF_CA_CA_exp_1      <- 0.2439314
l_params_owsa_max$prop_AF_CA_CA_exp_1      <- 0.2717558 
l_params_owsa_min$prop_AF_CA_CA_exp_2      <- 0.2843864
l_params_owsa_max$prop_AF_CA_CA_exp_2      <- 0.3713022  

# Confidence intervals of time to AF symptoms derived from survial curves of Vektis data
l_params_owsa_min$p_SFAF_CA_SAF_L1   <- trans_prob(df_s_ablation1[[1]]$lcl) 
l_params_owsa_max$p_SFAF_CA_SAF_L1   <- trans_prob(df_s_ablation1[[1]]$ucl) 
l_params_owsa_min$p_SFAF_CA_SAF_L2   <- trans_prob(df_s_ablation2[[1]]$lcl) 
l_params_owsa_max$p_SFAF_CA_SAF_L2   <- trans_prob(df_s_ablation2[[1]]$ucl) 
l_params_owsa_min$p_SFAF_CA_SAF_L3   <- trans_prob(df_s_ablation3[[1]]$lcl) 
l_params_owsa_max$p_SFAF_CA_SAF_L3   <- trans_prob(df_s_ablation3[[1]]$ucl) 

# Confidence intervals as reported by from Vinter et al.
l_params_owsa_min$HR_EM <- 1.71
l_params_owsa_max$HR_EM <- 2.36

# Confidence intervals derived from beta distribution of counts reported in ablation register of NHR in 2023
l_params_owsa_min$p_CT_CA      <- qbeta(0.025, n_CT_CA, n_tot_CT_CA-n_CT_CA)                 
l_params_owsa_max$p_CT_CA      <- qbeta(0.975, n_CT_CA, n_tot_CT_CA-n_CT_CA)  
l_params_owsa_min$p_PP_CA      <- qbeta(0.025, n_PP_CA, n_tot_PP_CA-n_PP_CA)                 
l_params_owsa_max$p_PP_CA      <- qbeta(0.975, n_PP_CA, n_tot_PP_CA-n_PP_CA)  
l_params_owsa_min$p_VC_CA      <- qbeta(0.025, n_VC_CA, n_tot_VC_CA-n_VC_CA)                 
l_params_owsa_max$p_VC_CA      <- qbeta(0.975, n_VC_CA, n_tot_VC_CA-n_VC_CA)  

# Vary coefficients productivity 
l_params_owsa_min$beta_reg_attendance_intercept <- beta_reg_attendance_intercept - qnorm(0.975) * 0.04763  
l_params_owsa_max$beta_reg_attendance_intercept <- beta_reg_attendance_intercept + qnorm(0.975) * 0.04763 
l_params_owsa_min$beta_reg_attendance_SAF       <- beta_reg_attendance_SAF - qnorm(0.975) * 0.08072    
l_params_owsa_max$beta_reg_attendance_SAF       <- beta_reg_attendance_SAF + qnorm(0.975) * 0.08072   

l_params_owsa_min$beta_reg_presenteeism_intercept <- beta_reg_presenteeism_intercept - qnorm(0.975) * 0.02500    
l_params_owsa_max$beta_reg_presenteeism_intercept <- beta_reg_presenteeism_intercept + qnorm(0.975) * 0.02500   
l_params_owsa_min$beta_reg_presenteeism_SAF       <- beta_reg_presenteeism_SAF - qnorm(0.975) * 0.04384      
l_params_owsa_max$beta_reg_presenteeism_SAF       <- beta_reg_presenteeism_SAF + qnorm(0.975) * 0.04384   

# Vary informal care coefficients based on SE in de Groot et al.
# Estimate coefficients of regression formula based on sampling from vcov and vary them separately
# Small adjustment to make the vcov "positive definite" to ensure it has certain mathematical properties that are required for multivariate normal sampling. The adjustments needed here were essentially zero (0.00000000000000000001%).
m_vcov_ic_log <- matrix(as.numeric(unlist(vcov_ic_log)), nrow = 5, ncol = 5)
vcov_ic_log_fixed <- as.matrix(nearPD(m_vcov_ic_log)$mat)

coef_samples_ic_log <- as.data.frame(mvrnorm(n = 1000, mu = params_ic_log, Sigma = vcov_ic_log_fixed))
params_ic_log_lower <- apply(coef_samples_ic_log, 2, function(x) {
  quantile(x, probs = 0.025)
})
params_ic_log_upper <- apply(coef_samples_ic_log, 2, function(x) {
  quantile(x, probs = 0.975)
})

coef_samples_ic_hours <- as.data.frame(mvrnorm(n = 1000, mu = params_ic_hours, Sigma = vcov_ic_hours[c(1:4), c(1:4)]))
params_ic_hours_lower <- apply(coef_samples_ic_hours, 2, function(x) {
  quantile(x, probs = 0.025)
})
params_ic_hours_upper <- apply(coef_samples_ic_hours, 2, function(x) {
  quantile(x, probs = 0.975)
})

l_params_owsa_min$params_ic_log_intercept <- params_ic_log_lower[1]
l_params_owsa_min$params_ic_log_female    <- params_ic_log_lower[2]
l_params_owsa_min$params_ic_log_age       <- params_ic_log_lower[3]
l_params_owsa_min$params_ic_log_age2      <- params_ic_log_lower[4]
l_params_owsa_min$params_ic_log_T2D       <- params_ic_log_lower[5]
l_params_owsa_max$params_ic_log_intercept <- params_ic_log_upper[1]
l_params_owsa_max$params_ic_log_female    <- params_ic_log_upper[2]
l_params_owsa_max$params_ic_log_age       <- params_ic_log_upper[3]
l_params_owsa_max$params_ic_log_age2      <- params_ic_log_upper[4]
l_params_owsa_max$params_ic_log_T2D       <- params_ic_log_upper[5]

l_params_owsa_min$params_ic_hours_intercept <- params_ic_hours_lower[1]
l_params_owsa_min$params_ic_hours_female    <- params_ic_hours_lower[2]
l_params_owsa_min$params_ic_hours_age       <- params_ic_hours_lower[3]
l_params_owsa_min$params_ic_hours_T2D       <- params_ic_hours_lower[4]
l_params_owsa_max$params_ic_hours_intercept <- params_ic_hours_upper[1]
l_params_owsa_max$params_ic_hours_female    <- params_ic_hours_upper[2]
l_params_owsa_max$params_ic_hours_age       <- params_ic_hours_upper[3]
l_params_owsa_max$params_ic_hours_T2D       <- params_ic_hours_upper[4]

# Confidence interval derived from standard deviation and sample size in van Dries et al. based on normal distribution
l_params_owsa_min$c_IC_77_AF_2yr            <- c_IC_77_AF_2yr - qnorm(0.975) * (321.76/sqrt(425))
l_params_owsa_max$c_IC_77_AF_2yr            <- c_IC_77_AF_2yr + qnorm(0.975) * (321.76/sqrt(425))

# Confidence interval derived from GLM model for coefficient of disutility of symptoms of AF
du_SAF_CI <- confint(glm_AVATARAF_NL, "sympAF_new", level = 0.95)
l_params_owsa_min$du_SAF <- abs(unname(du_SAF_CI[2]))
l_params_owsa_max$du_SAF <- abs(unname(du_SAF_CI[1]))

l_params_owsa_min$gen_pop_utility <- "lwr"
l_params_owsa_max$gen_pop_utility <- "upr"

# No confidence interval available, so varied +/- 20%
l_params_owsa_min$c_AAD    <- qlnorm(0.025, c_AAD_params$estimate[1], c_AAD_params$estimate[2])
l_params_owsa_max$c_AAD    <- qlnorm(0.975, c_AAD_params$estimate[1], c_AAD_params$estimate[2])
l_params_owsa_min$c_CA_DBC <- qweibull(0.025, shape = c_CA_DBC_params$estimate[1], scale = c_CA_DBC_params$estimate[2])
l_params_owsa_max$c_CA_DBC <- qweibull(0.975, shape = c_CA_DBC_params$estimate[1], scale = c_CA_DBC_params$estimate[2])

l_params_owsa_min$c_d_before_CA <- qnorm(0.025, c_d_before_CA, (c_sd_d_before_CA/sqrt(1495)))
l_params_owsa_max$c_d_before_CA <- qnorm(0.975, c_d_before_CA, (c_sd_d_before_CA/sqrt(1495)))
l_params_owsa_min$c_d_after_CA1 <- qnorm(0.025, c_d_after_CA1, (c_sd_d_after_CA1/sqrt(1495)))
l_params_owsa_max$c_d_after_CA1 <- qnorm(0.975, c_d_after_CA1, (c_sd_d_after_CA1/sqrt(1495)))
l_params_owsa_min$c_d_after_CA2 <- qnorm(0.025, c_d_after_CA2, (c_sd_d_after_CA2/sqrt(1495)))
l_params_owsa_max$c_d_after_CA2 <- qnorm(0.975, c_d_after_CA2, (c_sd_d_after_CA2/sqrt(1495)))
l_params_owsa_min$c_d_SAF       <- qnorm(0.025, c_d_SAF, (c_sd_d_SAF/sqrt(1495)))
l_params_owsa_max$c_d_SAF       <- qnorm(0.975, c_d_SAF, (c_sd_d_SAF/sqrt(1495)))

v_names_params_20perc <- c("prop_work_M", "prop_work_F", "v_hours_per_week_M",
                           "v_hours_per_week_F", "c_hourly_wage_2022", "c_IC_hr",
                           "LE_M_77", "LE_F_77", "du_CT_mo", "du_PP_mo", "du_VC_mo")
l_params_owsa_min[v_names_params_20perc] <- lapply(l_params[v_names_params_20perc], "*", lower) 
l_params_owsa_max[v_names_params_20perc] <- lapply(l_params[v_names_params_20perc], "*", upper) 

l_params_owsa_min$df_FMC[,3:4] <- l_params$df_FMC[,3:4]*lower
l_params_owsa_max$df_FMC[,3:4] <- l_params$df_FMC[,3:4]*upper

# Save base case values
l_params_owsa_bc  <- l_params

# Make a dataframe of the input parameters mean, min and max that are not strings, vectors of length >1 or dataframes or are not varied in OWSA
single_value_names <- v_names_params[!v_names_params %in% c("age", "prop_female", "sd_age", "v_age", "v_Sex", 
                                                            "p_SFAF_CA_SAF_L1", "p_SFAF_CA_SAF_L2", "p_SFAF_CA_SAF_L3", 
                                                             "df_FMC","gen_pop_utility",  "mod_splines_coef")]
mean_values <- min_values <- max_values <- NULL
for (i in 1:length(single_value_names)) {
  param_name <- single_value_names[i]
  mean_values[i] <- l_params[[param_name]]
  min_values[i] <- l_params_owsa_min[[param_name]]
  max_values[i] <- l_params_owsa_max[[param_name]]
}

df_owsa_params <- data.frame(
  parameter = single_value_names,
  mean = mean_values,
  min = min_values,
  max = max_values
)

# Add columns to check the relationships
df_owsa_params$min_less_than_mean <- df_owsa_params$min < df_owsa_params$mean
df_owsa_params$max_greater_than_mean <- df_owsa_params$max > df_owsa_params$mean

#View(df_owsa_params)

# Check values that are in a vector or dataframe
mean(l_params_owsa_min$v_age) < age
mean(l_params_owsa_max$v_age) > age

mean(l_params_owsa_min$v_Sex) < prop_female
mean(l_params_owsa_max$v_Sex) > prop_female

df_p_SFAF_CA_SAF_L1 <- data.frame(mean = l_params$p_SFAF_CA_SAF_L1,
                                  min = l_params_owsa_min$p_SFAF_CA_SAF_L1,
                                  max = l_params_owsa_max$p_SFAF_CA_SAF_L1)
df_p_SFAF_CA_SAF_L1$min_less_than_mean <- df_p_SFAF_CA_SAF_L1$min < df_p_SFAF_CA_SAF_L1$mean
df_p_SFAF_CA_SAF_L1$max_greater_than_mean <- df_p_SFAF_CA_SAF_L1$max > df_p_SFAF_CA_SAF_L1$mean
#View(df_p_SFAF_CA_SAF_L1)

df_p_SFAF_CA_SAF_L2 <- data.frame(mean = l_params$p_SFAF_CA_SAF_L2,
                                  min = l_params_owsa_min$p_SFAF_CA_SAF_L2,
                                  max = l_params_owsa_max$p_SFAF_CA_SAF_L2)
df_p_SFAF_CA_SAF_L2$min_less_than_mean <- df_p_SFAF_CA_SAF_L2$min < df_p_SFAF_CA_SAF_L2$mean
df_p_SFAF_CA_SAF_L2$max_greater_than_mean <- df_p_SFAF_CA_SAF_L2$max > df_p_SFAF_CA_SAF_L2$mean
#View(df_p_SFAF_CA_SAF_L2)

df_p_SFAF_CA_SAF_L3 <- data.frame(mean = l_params$p_SFAF_CA_SAF_L3,
                                  min = l_params_owsa_min$p_SFAF_CA_SAF_L3,
                                  max = l_params_owsa_max$p_SFAF_CA_SAF_L3)
df_p_SFAF_CA_SAF_L3$min_less_than_mean <- df_p_SFAF_CA_SAF_L3$min < df_p_SFAF_CA_SAF_L3$mean
df_p_SFAF_CA_SAF_L3$max_greater_than_mean <- df_p_SFAF_CA_SAF_L3$max > df_p_SFAF_CA_SAF_L3$mean
#View(df_p_SFAF_CA_SAF_L3)

df_FMC_other_y <- data.frame(mean = l_params$df_FMC$other_y,
                            min = l_params_owsa_min$df_FMC$other_y,
                            max = l_params_owsa_max$df_FMC$other_y)
df_FMC_other_y$min_less_than_mean <- df_FMC_other_y$min < df_FMC_other_y$mean
df_FMC_other_y$max_greater_than_mean <- df_FMC_other_y$max > df_FMC_other_y$mean
#View(df_FMC_other_y)

df_FMC_last_y <- data.frame(mean = l_params$df_FMC$last_y,
                            min = l_params_owsa_min$df_FMC$last_y,
                            max = l_params_owsa_max$df_FMC$last_y)
df_FMC_last_y$min_less_than_mean <- df_FMC_last_y$min < df_FMC_last_y$mean
df_FMC_last_y$max_greater_than_mean <- df_FMC_last_y$max > df_FMC_last_y$mean
#View(df_FMC_last_y)

df_c_states_min <- l_params_owsa_max$df_c_states[, 2:4] > l_params$df_c_states[, 2:4]
df_c_states_max <- l_params_owsa_min$df_c_states[, 2:4] < l_params$df_c_states[, 2:4]
# df_c_states_min
# df_c_states_max

```

## 05.2 Run the OWSA
NB: with n_i = 50000 this analyses took 6 hours using the workbenchjob_OWSA script on the Posit Workbench of Zorginstituut
```{r}
# Variables that can be set to T to return less results to decrease runtime
PSA         <- F
mainresults <- T # only returns tc_hat and te_hat

base_case_result_a     <- MicroSim(l_params, n_i, df_X, TRT1 = TRT1a, TRT2 = TRT2a, TRT3 = TRT3a, TRT4 = TRT4a, TRT5 = TRT5a, TRT6 = TRT6a, seed = 1)
base_case_result_a$NHB <- base_case_result_a$te_hat - (base_case_result_a$tc_hat/wtp)

base_case_result_b     <- MicroSim(l_params, n_i, df_X, TRT1 = TRT1b, TRT2 = TRT2b, TRT3 = TRT3b, TRT4 = TRT4b, TRT5 = TRT5b, TRT6 = TRT6a, seed = 1)
base_case_result_b$NHB <- base_case_result_b$te_hat - (base_case_result_b$tc_hat/wtp)

d_e <- base_case_result_a$te_hat-base_case_result_b$te_hat
d_c <- base_case_result_a$tc_hat-base_case_result_b$tc_hat
iNHB <- d_e - (d_c/wtp)

# Prepare list object for lapply to use
l_owsa <- list()
l_owsa <- rep(list(l_params),(length(v_names_params)*2))

for (i in 1:length(v_names_params)){
  l_owsa[[i]][[i]]                        <- l_params_owsa_min[[i]]
  l_owsa[[i+length(v_names_params)]][[i]] <- l_params_owsa_max[[i]]  
}

# Setup parallel processing with optimized memory management
num_cores <- min(detectCores() - 1, 4)  # Limit cores to prevent memory overload
cluster <- makeCluster(num_cores, type = "PSOCK")
registerDoParallel(cluster)

# Set memory limits and clean environment
clusterEvalQ(cluster, {
  options(future.globals.maxSize = 4 * 1024^3)  # 4GB per worker
  gc(reset = TRUE)
  library(dplyr) 
  library(darthtools)
  library(splines)
  source(here::here("functions", "functions.R"))
})

clusterExport(cluster, c('MicroSim', 'Create_df_X', 'n_i', 'rtruncnorm', 'v_n', 'n_states',
                         'n_t',  'Costs', 'Effs', 'Probs', 'PrepareProbs', 'PrepareCosts', 
                         'cl', 'v_dwc', 'v_dwe', 'v_wcc', 'min_age', 'max_age', 'PSA', 'mainresults',
                         'TRT1a','TRT2a','TRT3a','TRT4a', 'TRT5a', 'TRT6a', 
                         'TRT1b','TRT2b','TRT3b','TRT4b', 'TRT5b', 'TRT6b', 'df_mort',
                         'beta_reg_attendance', 'beta_reg_presenteeism', 'params_ic_log', 'params_ic_hours','mod_splines'))

# Process parameters in chunks
chunk_size <- ceiling(length(l_owsa) / (3 * num_cores))
l_owsa_chunks <- split(l_owsa, ceiling(seq_along(l_owsa)/chunk_size))

# Initialize results containers
l_results_owsa_a <- vector("list", length(l_owsa))
l_results_owsa_b <- vector("list", length(l_owsa))

tic()
# Process each chunk with clean-up between
for (i in seq_along(l_owsa_chunks)) {
  cat("Processing chunk", i, "of", length(l_owsa_chunks), "\n")
  # Treatment A chunk processing
  chunk_results_a <- parLapply(cluster, l_owsa_chunks[[i]], function(o){
    # Return minimal required data
    result <- MicroSim(o, n_i, df_X, 
                       TRT1 = TRT1a, TRT2 = TRT2a, TRT3 = TRT3a, TRT4 = TRT4a, TRT5 = TRT5a, TRT6 = TRT6a, 
                       seed = 1)
    list(tc_hat = result$tc_hat, te_hat = result$te_hat)
  })
  # Treatment B chunk processing
  chunk_results_b <- parLapply(cluster, l_owsa_chunks[[i]], function(o){
    result <- MicroSim(o, n_i, df_X, 
                       TRT1 = TRT1b, TRT2 = TRT2b, TRT3 = TRT3b, TRT4 = TRT4b, TRT5 = TRT5b, TRT6 = TRT6b, 
                       seed = 1)
    list(tc_hat = result$tc_hat, te_hat = result$te_hat)
  })
  # Store chunk results
  chunk_indices <- ((i-1) * chunk_size + 1):min(i * chunk_size, length(l_owsa))
  for (j in seq_along(chunk_indices)) {
    l_results_owsa_a[[chunk_indices[j]]] <- chunk_results_a[[j]]
    l_results_owsa_b[[chunk_indices[j]]] <- chunk_results_b[[j]]
  }
  # Free memory
  rm(chunk_results_a, chunk_results_b)
  gc(full = TRUE)
  # Save progress
  if (i %% 2 == 0 || i == length(l_owsa_chunks)) {
    saveRDS(list(a = l_results_owsa_a, b = l_results_owsa_b), 
            file = here::here("output", paste0("owsa_progress_", i, ".rds")))
  }
}
toc()

# Free cluster resources
stopCluster(cluster)

# Process results
process_results <- function(results_list, param_names, param_count, wtp) {
  # Split results for min and max values
  results_min <- results_list[1:param_count]
  results_max <- results_list[(param_count+1):(2*param_count)]
  # Extract values using vectorized operations
  results_df <- data.frame(
    Parameter = param_names,
    Lower_Bound_c = sapply(results_min, function(x) x$tc_hat),
    Lower_Bound_e = sapply(results_min, function(x) x$te_hat),
    Upper_Bound_c = sapply(results_max, function(x) x$tc_hat),
    Upper_Bound_e = sapply(results_max, function(x) x$te_hat)
  )

  results_df$Lower_Bound_NHB   <- results_df$Lower_Bound_e - (results_df$Lower_Bound_c/wtp)
  results_df$Upper_Bound_NHB   <- results_df$Upper_Bound_e - (results_df$Upper_Bound_c/wtp)
  results_df$UL_Difference_c   <- abs(results_df$Upper_Bound_c - results_df$Lower_Bound_c)
  results_df$UL_Difference_e   <- abs(results_df$Upper_Bound_e - results_df$Lower_Bound_e)
  results_df$UL_Difference_NHB <- abs(results_df$Upper_Bound_NHB - results_df$Lower_Bound_NHB)
  return(results_df)
}

# Process and save results for both treatments
results_owsa_a <- process_results(l_results_owsa_a, v_names_params, length(v_names_params), wtp)
write.csv(results_owsa_a, here::here("output", "results_owsa_a.csv"), row.names = FALSE)

results_owsa_b <- process_results(l_results_owsa_b, v_names_params, length(v_names_params), wtp)
write.csv(results_owsa_b, here::here("output", "results_owsa_b.csv"), row.names = FALSE)




```

## 05.3 Interpret results OWSA
```{r}

results_owsa_a <- read.csv(here::here("output", "results_owsa_a.csv"))
#View(results_owsa_a)

results_owsa_b <- read.csv(here::here("output", "results_owsa_b.csv"))
#View(results_owsa_b)

# Base case results not properly saved, but can be derived from the first row as age was not varied trough age but trough v_age
base_case_result_a_c <- results_owsa_a$Lower_Bound_c[1]
base_case_result_a_e <- results_owsa_a$Lower_Bound_e[1]
base_case_result_b_c <- results_owsa_b$Lower_Bound_c[1]
base_case_result_b_e <- results_owsa_b$Lower_Bound_e[1]
d_e <- base_case_result_a_e-base_case_result_b_e
d_c <- base_case_result_a_c-base_case_result_b_c
iNHB <- d_e - (d_c/wtp)

# Make results incremental
results_owsa_i <- results_owsa_a[, -c(6:10)]
results_owsa_i[,2:5] <- results_owsa_a[,2:5]-results_owsa_b[,2:5]
results_owsa_i$Lower_Bound_iNHB <- results_owsa_i$Lower_Bound_e - (results_owsa_i$Lower_Bound_c/wtp)
results_owsa_i$Upper_Bound_iNHB <- results_owsa_i$Upper_Bound_e - (results_owsa_i$Upper_Bound_c/wtp)

results_owsa_i$UL_Difference_c   <- abs(results_owsa_i$Upper_Bound_c-results_owsa_i$Lower_Bound_c)
results_owsa_i$UL_Difference_e   <- abs(results_owsa_i$Upper_Bound_e-results_owsa_i$Lower_Bound_e)
results_owsa_i$UL_Difference_NHB <- abs(results_owsa_i$Upper_Bound_iNHB-results_owsa_i$Lower_Bound_iNHB)

# Remove first three rows for age, sd_age and prop_female as they were varied with v_age and v_Sex in the OWSA
results_owsa_i <- results_owsa_i[-c(1:3), ]
# Remove mod_splines_coef, included via gen_pop_utility in OWSA
results_owsa_i <- results_owsa_i[-nrow(results_owsa_i), ]

v_names_params_clean <- c("Age", 
                                "Proportion females", 
                                "Proportion paroxysmal AF", 
                                "RR AF recurrence after 1st CA in AAD naive pts", 
                                "RR AF recurrence after 1st CA in AAD-exposed paroxysmal AF pts", 
                                "RR AF recurrence after 1st CA in AAD-exposed persistent AF pts", 
                                "RR AF recurrence after >=2 CA", 
                                "Proportion AF recurrence after 1st CA in AAD naive pts", 
                                "Proportion AF recurrence after 1st CA in AAD-exposed paroxysmal AF pts" ,  
                                "Proportion AF recurrence after 1st CA in AAD-exposed persistent AF pts", 
                                "Proportion AF recurrence after 2nd CA in exposed pts", 
                                "Proportion AF recurrence after >=3 CA in exposed pts", 
                                "Probability long-term AF recurrence after 1st CA", 
                                "Probability long-term AF recurrence after 2nd CA",  
                                "Probability long-term AF recurrence after >=3 CA",        
                                "HR excess mortality AF patients", 
                                "Probability of discontinuation AADs in naive pts", 
                                "Probability of discontinuation AADs in exposed pts", 
                                "Probability of cardiac tamponade after CA",  
                                "Probability of phrenicus paralysis after CA",                    
                                "Probability of vascular complications after CA", 
                                "Intervention costs AAD", 
                                "Intervention costs CA", 
                                "Healthcare costs of preparation of CA",
                                "Healthcare costs of follow-up CA (0-6 months)",               
                                "Healthcare costs of follow-up CA (7-12 months)", 
                                "Healthcare costs of AF symptoms", 
                                "Other health care costs (unrelated to AF and last year of life)",
                                "Labour participation males",  
                                "Labour participation females",                
                                "Average work hours/week males", 
                                "Average work hours/week females" , 
                                "Average hourly wage", 
                                "Regression model informal care probability - intercept",  
                                "Regression model informal care probability - female",       
                                "Regression model informal care probability - age", 
                                "Regression model informal care probability - age^2" , 
                                "Regression model informal care probability - time to death", 
                                "Regression model informal care hours/day - intercept",  
                                "Regression model informal care hours/day - female",     
                                "Regression model informal care hours/day - age", 
                                "Regression model informal care hours/day - time to death", 
                                "Regression model work attendance - intercept", 
                                "Regression model work attendance - AF symptoms",  
                                "Regression model work presenteeism - intercept",
                                "Regression model work presenteeism - AF symptoms", 
                                "Life expectancy 77 year-old male", 
                                "Life expectancy 77 year-old female", 
                                "Hourly costs of informal care",  
                                "Two-year costs of informal care AF patients",            
                                "Disutility of AF symptoms", 
                                "Disutility of cardiac tamponade", 
                                "Disutility of phrenicus paralysis", 
                                "Disutility of vascular complications",  
                                "General population utilities")

results_owsa_i$Parameter <- v_names_params_clean

# Save results
write.csv(results_owsa_i, here::here("output", "results_owsa_i.csv"))

# Separate in data frames per outcome for tornado diagrams
results_owsa_c <- results_owsa_i[ , c(1,2,4,8)]
colnames(results_owsa_c) <- c("Parameter", "Lower_Bound", "Upper_Bound", "UL_Difference")

results_owsa_e <- results_owsa_i[ , c(1,3,5,9)]
colnames(results_owsa_e) <- c("Parameter", "Lower_Bound", "Upper_Bound", "UL_Difference")

results_owsa_NHB <- results_owsa_i[ , c(1,6,7,10)]
colnames(results_owsa_NHB) <- c("Parameter", "Lower_Bound", "Upper_Bound", "UL_Difference")

```


## 05.4 Tornado diagrams
### 05.4.1 Costs
```{r}
library(scales)
knitr::opts_chunk$set(eval = FALSE)
results_owsa <- results_owsa_c
results_owsa <- results_owsa[results_owsa$UL_Difference > 10, ]
base_case    <- d_c 

order.parameters <- results_owsa %>% arrange(UL_Difference) %>%
  mutate(Parameter=factor(x=Parameter, levels=Parameter)) %>% 
  dplyr::select(Parameter) %>% unlist() %>% levels() 

# width of columns in plot (value between 0 and 1)
width <- 0.90

# get data frame in shape for ggplot and geom_rect
results_owsa.2 <- results_owsa %>%
  # gather columns Lower_Bound and Upper_Bound into a single column using gather
  gather(key='type', value='output.value', Lower_Bound:Upper_Bound) %>%
  # just reordering columns
  dplyr::select(Parameter, type, output.value, UL_Difference) %>%
  # create the columns for geom_rect
  mutate(Parameter=factor(Parameter, levels=order.parameters),
         ymin=pmin(output.value, base_case),
         ymax=pmax(output.value, base_case),
         xmin=as.numeric(Parameter)-width/2,
         xmax=as.numeric(Parameter)+width/2)

# create plot
# (use scale_x_continuous to change labels in y axis to name of parameters)
ggplot() + 
  geom_rect(data = results_owsa.2, 
            aes(ymax=ymax, ymin=ymin, xmax=xmax, xmin=xmin, fill=type)) +
  ylab("Incremental costs") +
  theme_bw() + 
  theme(axis.title.y=element_blank(), legend.position = 'right',
        legend.title = element_blank()) + 
  geom_hline(yintercept = base_case) +
  scale_x_continuous(breaks = c(1:length(order.parameters)), 
                     labels = order.parameters) +
  scale_y_continuous(labels = dollar_format(prefix = "", big.mark=",", decimal.mark = ".")) +
  scale_fill_manual(labels=c("Lower value", "Upper value"), values = c("#49870c", "#42145f")) +
  theme(text=element_text(size=10), axis.text.y = element_text(size = 10), legend.position = "bottom")+
  coord_flip()

#ggsave(here::here("output", "tornado_diagram_costs.png"), width = 16, height = 16, units = c("cm"), dpi = 300)
```

### 05.4.2 Effects
```{r}
knitr::opts_chunk$set(eval = FALSE)
results_owsa <- results_owsa_e 
results_owsa <- results_owsa[results_owsa$UL_Difference > 0.00001, ]
base_case    <- d_e

order.parameters <- results_owsa %>% arrange(UL_Difference) %>%
  mutate(Parameter=factor(x=Parameter, levels=Parameter)) %>% 
  dplyr::select(Parameter) %>% unlist() %>% levels() 

# width of columns in plot (value between 0 and 1)
width <- 0.90

# get data frame in shape for ggplot and geom_rect
results_owsa.2 <- results_owsa %>%
  # gather columns Lower_Bound and Upper_Bound into a single column using gather
  gather(key='type', value='output.value', Lower_Bound:Upper_Bound) %>%
  # just reordering columns
  dplyr::select(Parameter, type, output.value, UL_Difference) %>%
  # create the columns for geom_rect
  mutate(Parameter=factor(Parameter, levels=order.parameters),
         ymin=pmin(output.value, base_case),
         ymax=pmax(output.value, base_case),
         xmin=as.numeric(Parameter)-width/2,
         xmax=as.numeric(Parameter)+width/2)

# create plot
# (use scale_x_continuous to change labels in y axis to name of parameters)
ggplot() + 
  geom_rect(data = results_owsa.2, 
            aes(ymax=ymax, ymin=ymin, xmax=xmax, xmin=xmin, fill=type)) +
  ylab("Incremental QALYs") +
  theme_bw() + 
  theme(axis.title.y=element_blank(), legend.position = 'right',
        legend.title = element_blank()) + 
  geom_hline(yintercept = base_case) +
  scale_x_continuous(breaks = c(1:length(order.parameters)), 
                     labels = order.parameters) +
  scale_fill_manual(labels=c("Lower value", "Upper value"), values = c("#49870c", "#42145f")) +
  theme(text=element_text(size=10), axis.text.y = element_text(size = 10), legend.position = "bottom")+
  coord_flip()

#ggsave(here::here("output", "tornado_diagram_effects.png"), width = 16, height = 16, units = c("cm"), dpi = 300)
```

### 05.4.3 NHB
```{r}
knitr::opts_chunk$set(eval = FALSE)
results_owsa <- results_owsa_NHB
results_owsa <- results_owsa[results_owsa$UL_Difference > 0.01, ]
base_case    <- iNHB

order.parameters <- results_owsa %>% arrange(UL_Difference) %>%
  mutate(Parameter=factor(x=Parameter, levels=Parameter)) %>% 
  dplyr::select(Parameter) %>% unlist() %>% levels() 

# width of columns in plot (value between 0 and 1)
width <- 0.90

# get data frame in shape for ggplot and geom_rect
results_owsa.2 <- results_owsa %>%
  # gather columns Lower_Bound and Upper_Bound into a single column using gather
  gather(key='type', value='output.value', Lower_Bound:Upper_Bound) %>%
  # just reordering columns
  dplyr::select(Parameter, type, output.value, UL_Difference) %>%
  # create the columns for geom_rect
  mutate(Parameter=factor(Parameter, levels=order.parameters),
         ymin=pmin(output.value, base_case),
         ymax=pmax(output.value, base_case),
         xmin=as.numeric(Parameter)-width/2,
         xmax=as.numeric(Parameter)+width/2)

# create plot
# (use scale_x_continuous to change labels in y axis to name of parameters)
ggplot() + 
  geom_rect(data = results_owsa.2, 
            aes(ymax=ymax, ymin=ymin, xmax=xmax, xmin=xmin, fill=type)) +
  ylab("iNHB") +
  theme_bw() + 
  theme(axis.title.y=element_blank(), legend.position = 'right',
        legend.title = element_blank()) + 
  geom_hline(yintercept = base_case) +
  scale_x_continuous(breaks = c(1:length(order.parameters)), 
                     labels = order.parameters) +
  scale_fill_manual(labels=c("Lower value", "Upper value"), values = c("#49870c", "#42145f")) +
  theme(text=element_text(size=10), axis.text.y = element_text(size = 10), legend.position = "bottom")+
  coord_flip()

ggsave(here::here("visual output", "tornado_diagram_NHB.png"), width = 20, height = 15, units = c("cm"), dpi = 300)

```

## 05.5 Export table with input and results OWSA
```{r}

# Replace input parameters that are strings, vectors of length >1 or dataframes or are not varied in OWSA with NA
l_params_owsa_min[["sd_age"]]           <- NA
l_params_owsa_min[["v_age"]]            <- NA
l_params_owsa_min[["v_Sex"]]            <- NA
l_params_owsa_min[["p_SFAF_CA_SAF_L1"]] <- NA
l_params_owsa_min[["p_SFAF_CA_SAF_L2"]] <- NA
l_params_owsa_min[["p_SFAF_CA_SAF_L3"]] <- NA
l_params_owsa_min[["df_FMC"]]           <- NA
l_params_owsa_min[["gen_pop_utility"]]  <- NA
l_params_owsa_min[["mod_splines_coef"]] <- NA

l_params_owsa_max[["sd_age"]]           <- NA
l_params_owsa_max[["v_age"]]            <- NA
l_params_owsa_max[["v_Sex"]]            <- NA
l_params_owsa_max[["p_SFAF_CA_SAF_L1"]] <- NA
l_params_owsa_max[["p_SFAF_CA_SAF_L2"]] <- NA
l_params_owsa_max[["p_SFAF_CA_SAF_L3"]] <- NA
l_params_owsa_max[["df_FMC"]]           <- NA
l_params_owsa_max[["gen_pop_utility"]]  <- NA
l_params_owsa_max[["mod_splines_coef"]] <- NA

mean_values <- min_values <- max_values <- NULL
for (i in 1:length(v_names_params)) {
  param_name <- v_names_params[i]
  min_values[i] <- l_params_owsa_min[[param_name]]
  max_values[i] <- l_params_owsa_max[[param_name]]
}

df_owsa_params <- data.frame(
  parameter = v_names_params,
  min = min_values,
  max = max_values
)

df_owsa_params <- df_owsa_params[-c(2,4,5,59), ]
df_owsa_params$parameter <- v_names_params_clean
colnames(df_owsa_params) <- c("Parameter", "Parameter value low", "Parameter value high")

table_results_owsa <- results_owsa_i[ , c(1, 6,7,10)]

table_owsa <- inner_join(df_owsa_params, table_results_owsa, by = "Parameter")
#View(table_owsa)

table_owsa <- table_owsa %>%
  arrange(desc(UL_Difference_NHB))

# Create a flextable object
ft <- flextable(table_owsa)

# Customize the table (optional)
ft <- autofit(ft)  # Automatically adjust column widths
#ft <- theme_vanilla(ft)  # Apply a theme

ft <- colformat_double(ft, j = "Parameter value low", digits = 3, big.mark = ",")   
ft <- colformat_double(ft, j = "Parameter value high", digits = 3, big.mark = ",")   
ft <- colformat_double(ft, j = "Lower_Bound_iNHB", digits = 3) 
ft <- colformat_double(ft, j = "Upper_Bound_iNHB", digits = 3) 
ft <- colformat_double(ft, j = "UL_Difference_NHB", digits = 3) 

# Save to Word document
doc <- read_docx()  # Create a new Word document
doc <- body_add_flextable(doc, value = ft)  # Add the table to the document
print(doc, target = here::here("output", "owsa.docx"))  # Save the document


```

# 06 PSA
## 06.1 Define PSA sequences
```{r}
# Define sequences you wish to compare
# It is also possible to perform the PSA for all sequences, but this takes approximately 4-5 days
df_trtseq   <-  data.frame(line1=c("AAD", "CA" ),
                           line2=c("AAD", "AAD"),
                           line3=c("AAD", "AAD"),
                           line4=c("AAD", "AAD"),
                           line5=c("AAD", "AAD"),
                           line6=c("CA" , "CA" ), stringsAsFactors = FALSE)
v_names_str <- c(paste(df_trtseq$line1, df_trtseq$line2, df_trtseq$line3,
                       df_trtseq$line4, df_trtseq$line5, df_trtseq$line6, sep="-"))
n_str       <- length(v_names_str)      

```

## 06.2 Define input values
```{R}
# PSA settings
n_sim <- 1000  # Number of simulations 
n_i   <- 5000  # Number of patients 

# generate input data
set.seed(071818)    

gen_psa <- function(n_sim = 100, seed = 071818){
  with((l_params), {
    set.seed(seed) # set a seed to be able to reproduce the same results
    
    # Informal care & productivity: estimate coefficients here using the vcov
    # Include the new coefficient in separate vectors per variable below
    params_ic_log_psa            <- mvrnorm(n_sim, params_ic_log, nearPD(as.matrix(vcov_ic_log))$mat) 
    params_ic_hours_psa          <- mvrnorm(n_sim, params_ic_hours, vcov_ic_hours[1:4,1:4]) 
    beta_reg_attendance_psa      <- mvrnorm(n_sim, beta_reg_attendance$coefficients$mean, vcov_beta_reg_attendance[-3,-3])
    beta_reg_presenteeism_psa    <- mvrnorm(n_sim, beta_reg_presenteeism$coefficients$mean, vcov_beta_reg_presenteeism[-3,-3])
    
    df_psa <- data.frame(
      prop_parox                          = rbeta(n_sim, n_paroxysmal, n_persistent), 
      RR_nai                              = rlnorm(n_sim, predrema1$pred, predrema1$se),
      RR_AAD_exp_parox                    = rlnorm(n_sim, predrema2$pred, predrema2$se),
      RR_AAD_exp_pers                     = rlnorm(n_sim, predrema3$pred, predrema3$se),
      RR_CA_exp                           = rlnorm(n_sim, log(RR_CA_exp), (log(2.80)-log(1.61))/(2*1.96)),
      prop_AF_CA_nai                      = plogis(rlogis(n_sim, predrema1i$pred, predrema1i$se)), 
      prop_AF_CA_AAD_exp_parox            = plogis(rlogis(n_sim, predrema2i$pred, predrema2i$se)),
      prop_AF_CA_AAD_exp_pers             = plogis(rlogis(n_sim, predrema3i$pred, predrema3i$se)),
      prop_AF_CA_CA_exp_1                 = rnorm(n_sim, prop_AF_CA_CA_exp_1, (0.2717558-0.2439314) / (2*1.96)), 
      prop_AF_CA_CA_exp_2                 = rnorm(n_sim, prop_AF_CA_CA_exp_2, (0.3713022-0.2843864) / (2*1.96)),  
      HR_EM                               = exp(rnorm(n_sim, log(HR_EM), (log(2.36)-log(1.71))/(2*1.96))),
      p_disc_AAD_nai                      = rbeta(n_sim, 12, 99-12),
      p_disc_AAD_exp                      = plogis(rlogis(n_sim, pred_disc$pred, pred_disc$se)), 
      p_CT_CA                             = rbeta(n_sim, n_CT_CA, n_tot_CT_CA-n_CT_CA),                 
      p_PP_CA                             = rbeta(n_sim, n_PP_CA, n_tot_PP_CA-n_PP_CA),                 
      p_VC_CA                             = rbeta(n_sim, n_VC_CA, n_tot_VC_CA-n_VC_CA), 
      c_AAD                               = rlnorm(n_sim, c_AAD_params$estimate[1], c_AAD_params$estimate[2]), 
      c_CA_DBC                            = rweibull(n_sim, shape = c_CA_DBC_params$estimate[1],               
                                                     scale = c_CA_DBC_params$estimate[2]),  
      c_d_before_CA                       = rnorm(n_sim, c_d_before_CA, (c_sd_d_before_CA/sqrt(1495))), 
      c_d_after_CA1                       = rnorm(n_sim, c_d_after_CA1, (c_sd_d_after_CA1/sqrt(1495))), 
      c_d_after_CA2                       = rnorm(n_sim, c_d_after_CA2, (c_sd_d_after_CA2/sqrt(1495))), 
      c_d_SAF                             = rnorm(n_sim, c_d_SAF, (c_sd_d_SAF/sqrt(1495))),
      prop_work_M                         = prop_work_M        , # not varied in PSA, based on CBS data in whole Dutch population
      prop_work_F                         = prop_work_F        , # not varied in PSA, based on CBS data in whole Dutch population
      v_hours_per_week_M                  = v_hours_per_week_M , # not varied in PSA, based on CBS data in whole Dutch population
      v_hours_per_week_F                  = v_hours_per_week_F , # not varied in PSA, based on CBS data in whole Dutch population
      c_hourly_wage_2022                  = c_hourly_wage_2022 , # not varied in PSA, based on CBS data in whole Dutch population
      params_ic_log_intercept             = params_ic_log_psa[,1],
      params_ic_log_female                = params_ic_log_psa[,2],
      params_ic_log_age                   = params_ic_log_psa[,3],
      params_ic_log_age2                  = params_ic_log_psa[,4],
      params_ic_log_T2D                   = params_ic_log_psa[,5],
      params_ic_hours_intercept           = params_ic_hours_psa[,1],
      params_ic_hours_female              = params_ic_hours_psa[,2], 
      params_ic_hours_age                 = params_ic_hours_psa[,3],
      params_ic_hours_T2D                 = params_ic_hours_psa[,4],
      beta_reg_attendance_intercept       = beta_reg_attendance_psa[,1],
      beta_reg_attendance_SAF             = beta_reg_attendance_psa[,2],
      beta_reg_presenteeism_intercept     = beta_reg_presenteeism_psa[,1],
      beta_reg_presenteeism_SAF           = beta_reg_presenteeism_psa[,2],
      LE_M_77                             = LE_M_77        , # not varied in PSA, based on CBS data in whole Dutch population
      LE_F_77                             = LE_F_77        , # not varied in PSA, based on CBS data in whole Dutch population
      c_IC_hr                             = c_IC_hr        , # not varied in PSA
      c_IC_77_AF_2yr                      = rgamma(n_sim, shape = c_IC_77_AF_2yr_gamma$shape, scale = c_IC_77_AF_2yr_gamma$scale), 
      du_SAF                              = -mvrnorm(n_sim,glm_AVATARAF_NL$coefficients, vcov_glm_AVATARAF_NL)[,2],
      du_CT_mo                            = du_CT_mo,
      du_PP_mo                            = du_PP_mo,
      du_VC_mo                            = du_VC_mo
    )
    
    return(df_psa)
  }
  )
}

# # test run the PSA function
# gen_psa(10) 

# Generate PSA input dataset
df_psa_input <- gen_psa(n_sim = n_sim)

# # First six observations
# head(df_psa_input)

### Create other PSA input not within dataframe ###
set.seed(071818)  

#baseline population
patient_pop <- list()
for(i in 1:n_sim) {
  patient_pop[[i]] <- list(
    set.seed = i,
    v_age = round(rtruncnorm(n_i, min_age, max_age, age, sd_age)),
    v_Sex = rbinom(n_i, 1, prop_female)
  )
}

# Baseline utilities
mod_splines_psa                  <- mvrnorm(n_sim, coef(mod_splines), vcov_splines) 
apply(mod_splines_psa, 1, min)
summary(apply(mod_splines_psa, 1, max))

# Time to event probabilities
times  <- seq(0, 100, 0.5)
df_s_ablation1_PSA <- df_s_ablation2_PSA <- df_s_ablation3_PSA <- data.frame(times = times) # prepare dataframe survival
p_SFAF_CA_SAF_L1_PSA <- p_SFAF_CA_SAF_L2_PSA <- p_SFAF_CA_SAF_L3_PSA <- data.frame(times = times) # prepare dataframe transition prob

# Copy base case survival function, these will be overwritten in de PSA
best_fit_ablation1_PSA <- best_fit_ablation1  
best_fit_ablation2_PSA <- best_fit_ablation2 
best_fit_ablation3_PSA <- best_fit_ablation3 

# Sample parameters of the survival objects for the PSA
best_fit_ablation1_sample <- normboot.flexsurvreg(best_fit_ablation1, B = n_sim) # sample parameters     
best_fit_ablation2_sample <- normboot.flexsurvreg(best_fit_ablation2, B = n_sim) #sample parameters
best_fit_ablation3_sample <- normboot.flexsurvreg(best_fit_ablation3, B = n_sim) #sample parameters

for(i in 1:n_sim){
  best_fit_ablation1_PSA$res.t[,1] <- best_fit_ablation1_sample[i,] 
  best_fit_ablation2_PSA$res.t[,1] <- best_fit_ablation2_sample[i,] 
  best_fit_ablation3_PSA$res.t[,1] <- best_fit_ablation3_sample[i,] 
  
  df_s_ablation1_PSA[,i+1]        <- summary(best_fit_ablation1_PSA, t = times)[[1]][2] # i + 1 because first column is time
  p_SFAF_CA_SAF_L1_PSA[,i+1]      <- c(NA,trans_prob(df_s_ablation1_PSA[,i+1])) # i + 1 because first column is time
  
  df_s_ablation2_PSA[,i+1]        <- summary(best_fit_ablation2_PSA, t = times)[[1]][2] 
  p_SFAF_CA_SAF_L2_PSA[,i+1]      <- c(NA,trans_prob(df_s_ablation2_PSA[,i+1]))
  
  df_s_ablation3_PSA[,i+1]        <- summary(best_fit_ablation3_PSA, t = times)[[1]][2] 
  p_SFAF_CA_SAF_L3_PSA[,i+1]      <- c(NA,trans_prob(df_s_ablation3_PSA[,i+1]))
  
}

p_SFAF_CA_SAF_L1_PSA                    <- p_SFAF_CA_SAF_L1_PSA[,-1]
p_SFAF_CA_SAF_L2_PSA                    <- p_SFAF_CA_SAF_L2_PSA[,-1]
p_SFAF_CA_SAF_L3_PSA                    <- p_SFAF_CA_SAF_L3_PSA[,-1]

p_SFAF_CA_SAF_L1_PSA                    <- p_SFAF_CA_SAF_L1_PSA[-1,]
p_SFAF_CA_SAF_L2_PSA                    <- p_SFAF_CA_SAF_L2_PSA[-1,]
p_SFAF_CA_SAF_L3_PSA                    <- p_SFAF_CA_SAF_L3_PSA[-1,]

# summary(apply(p_SFAF_CA_SAF_L1_PSA, 1, min))
# summary(apply(p_SFAF_CA_SAF_L2_PSA, 1, min))
# summary(apply(p_SFAF_CA_SAF_L3_PSA, 1, min))
# 
# summary(apply(p_SFAF_CA_SAF_L1_PSA, 1, max))
# summary(apply(p_SFAF_CA_SAF_L2_PSA, 1, max))
# summary(apply(p_SFAF_CA_SAF_L3_PSA, 1, max))

# Initialize dataframes with PSA output
# Data frame of costs
df_c             <- as.data.frame(matrix(0, nrow = n_sim,  ncol = n_str))
colnames(df_c)   <- v_names_str

# Data frame of effectiveness
df_e             <- as.data.frame(matrix(0, nrow = n_sim, ncol = n_str))
colnames(df_e)   <- v_names_str


```

## 06.3 Run the PSA
```{R}
# Variables that can be set to T to return less results to decrease runtime
PSA         <- T
mainresults <- F # only returns tc_hat and te_hat

# Setup parallel processing
num_cores          <- detectCores() - 1  # Leave one core free for system processes
cluster            <- makeCluster(num_cores)
registerDoParallel(cluster)

clusterExport(cluster, c('MicroSim', 'Create_df_X', 'n_i', 'rtruncnorm', 'v_n', 'n_states',
                         'n_t',  'Costs', 'Effs', 'Probs', 'PrepareProbs', 'PrepareCosts', 
                         'cl', 'v_dwc', 'v_dwe', 'v_wcc', 'min_age', 'max_age', 'PSA',
                         'gen_pop_utility', 'mod_splines'))

clusterEvalQ(cluster, 
             {library(dplyr) 
               library(darthtools)
               library(splines)
               source(here::here("functions", "functions.R"))
             })

iterations <- nrow(df_trtseq)
pb         <- txtProgressBar(max = iterations, style = 3)
progress   <- function(n) setTxtProgressBar(pb, n)
opts       <- list(progress = progress)
pb = txtProgressBar(min = 0, max = n_sim, initial = 0)

tic()
for(i in 1:n_sim){
  
  l_params                    <- list(
    prop_parox                         = df_psa_input$prop_parox[i]                         ,  
    RR_nai                             = df_psa_input$RR_nai[i]                             ,  
    RR_AAD_exp_parox                   = df_psa_input$RR_AAD_exp_parox[i]                   ,  
    RR_AAD_exp_pers                    = df_psa_input$RR_AAD_exp_pers[i]                    ,  
    RR_CA_exp                          = df_psa_input$RR_CA_exp[i]                          ,  
    prop_AF_CA_nai                     = df_psa_input$prop_AF_CA_nai[i]                     ,  
    prop_AF_CA_AAD_exp_parox           = df_psa_input$prop_AF_CA_AAD_exp_parox[i]           ,  
    prop_AF_CA_AAD_exp_pers            = df_psa_input$prop_AF_CA_AAD_exp_pers[i]            ,  
    prop_AF_CA_CA_exp_1                = df_psa_input$prop_AF_CA_CA_exp_1[i]                ,  
    prop_AF_CA_CA_exp_2                = df_psa_input$prop_AF_CA_CA_exp_2[i]                ,  
    HR_EM                              = df_psa_input$HR_EM[i]                              ,  
    p_disc_AAD_nai                     = df_psa_input$p_disc_AAD_nai[i]                     ,  
    p_disc_AAD_exp                     = df_psa_input$p_disc_AAD_exp[i]                     ,  
    p_CT_CA                            = df_psa_input$p_CT_CA[i]                            ,  
    p_PP_CA                            = df_psa_input$p_PP_CA[i]                            ,  
    p_VC_CA                            = df_psa_input$p_VC_CA[i]                            ,  
    c_AAD                              = df_psa_input$c_AAD[i]                              ,  
    c_CA_DBC                           = df_psa_input$c_CA_DBC[i]                           ,  
    c_d_before_CA                      = df_psa_input$c_d_before_CA[i]                      ,  
    c_d_after_CA1                      = df_psa_input$c_d_after_CA1[i]                      ,  
    c_d_after_CA2                      = df_psa_input$c_d_after_CA2[i]                      ,  
    c_d_SAF                            = df_psa_input$c_d_SAF[i]                            ,  
    prop_work_M                        = df_psa_input$prop_work_M[i]                        ,  
    prop_work_F                        = df_psa_input$prop_work_F[i]                        ,  
    v_hours_per_week_M                 = df_psa_input$v_hours_per_week_M[i]                 ,  
    v_hours_per_week_F                 = df_psa_input$v_hours_per_week_F[i]                 ,  
    c_hourly_wage_2022                 = df_psa_input$c_hourly_wage_2022[i]                 ,  
    params_ic_log_intercept            = df_psa_input$params_ic_log_intercept[i]            ,  
    params_ic_log_female               = df_psa_input$params_ic_log_female[i]               ,  
    params_ic_log_age                  = df_psa_input$params_ic_log_age[i]                  ,  
    params_ic_log_age2                 = df_psa_input$params_ic_log_age2[i]                 ,  
    params_ic_log_T2D                  = df_psa_input$params_ic_log_T2D[i]                  ,  
    params_ic_hours_intercept          = df_psa_input$params_ic_hours_intercept[i]          ,  
    params_ic_hours_female             = df_psa_input$params_ic_hours_female[i]             ,  
    params_ic_hours_age                = df_psa_input$params_ic_hours_age[i]                ,  
    params_ic_hours_T2D                = df_psa_input$params_ic_hours_T2D[i]                ,  
    beta_reg_attendance_intercept      = df_psa_input$beta_reg_attendance_intercept[i]      ,  
    beta_reg_attendance_SAF            = df_psa_input$beta_reg_attendance_SAF[i]            ,  
    beta_reg_presenteeism_intercept    = df_psa_input$beta_reg_presenteeism_intercept[i]    ,  
    beta_reg_presenteeism_SAF          = df_psa_input$beta_reg_presenteeism_SAF[i]          ,  
    LE_M_77                            = df_psa_input$LE_M_77[i]                            ,  
    LE_F_77                            = df_psa_input$LE_F_77[i]                            ,  
    c_IC_hr                            = df_psa_input$c_IC_hr[i]                            ,  
    c_IC_77_AF_2yr                     = df_psa_input$c_IC_77_AF_2yr[i]                     ,  
    du_SAF                             = df_psa_input$du_SAF[i]                             ,  
    du_CT_mo                           = df_psa_input$du_CT_mo[i]                           ,  
    du_PP_mo                           = df_psa_input$du_PP_mo[i]                           ,  
    du_VC_mo                           = df_psa_input$du_VC_mo[i]                           ,  
    mod_splines_coef                   = mod_splines_psa[i,],
    p_SFAF_CA_SAF_L1                   = p_SFAF_CA_SAF_L1_PSA[,i], 
    p_SFAF_CA_SAF_L2                   = p_SFAF_CA_SAF_L2_PSA[,i], 
    p_SFAF_CA_SAF_L3                   = p_SFAF_CA_SAF_L3_PSA[,i],
    v_age                              = patient_pop[[i]]$v_age,
    v_Sex                              = patient_pop[[i]]$v_Sex,
    df_FMC                             = df_FMC
  )       
  
  if(any(is.na(l_params))) {   
    na_params <- names(l_params)[sapply(l_params, function(x) any(is.na(x)))]   
    stop(paste("NA values detected in parameters:", paste(na_params, collapse=", "))) 
  }
  
  tic()
  tryCatch({
    results <- foreach(g = 1:nrow(df_trtseq), 
                       .packages = c("darthtools")) %dopar% {
                         MicroSim(l_params, n_i, df_X, TRT1 = df_trtseq[g,1], TRT2 = df_trtseq[g,2], 
                                  TRT3 = df_trtseq[g,3], TRT4 = df_trtseq[g,4], TRT5 = df_trtseq[g,5], 
                                  TRT6 = df_trtseq[g,6], seed = 1)
                       }
  }, error = function(e) {
    # Log detailed information about the failed iteration
    cat("Error in iteration", i, ":\n")
    cat("Parameter values:\n")
    print(l_params)
    cat("Error message:", e$message, "\n")
    # Return NA or some baseline results instead of stopping
    return(NULL)
  })
  
  # Check if results is NULL before proceeding
  if (!is.null(results)) {
    # Process results normally
  }
  
  
  temp_v_C <- NULL
  for (j in 1:length(results)){
    temp_v_C[j]<- results[[j]]$tc_hat
  }
  
  temp_v_E <- NULL
  for (j in 1:length(results)){
    temp_v_E[j]<- results[[j]]$te_hat
  }
  
  df_c[i, ] <- c(temp_v_C)   # take the cost from the psa run and store in df_c
  df_e[i, ] <- c(temp_v_E)   # take the effect from the psa run in store in a df_e
  
  
  setTxtProgressBar(pb,i) # Display simulation progress                       
}
toc()

# Stop using multiple cores
stopCluster(cluster)

# Save results
psa_seq_results           <- data.frame(cost   = gather(df_c, key = treatment, value = costs),  
                                        effect = gather(df_e, key = treatment, value = effect))
psa_seq_results           <- psa_seq_results[, -3]
colnames(psa_seq_results) <- c("treatment", "costs", "effects")
psa_seq_results$NHB       <- psa_seq_results$effects - (psa_seq_results$costs/wtp) 

# Save results
write.csv(psa_seq_results, here::here("output", "results_psa_best_AAD_CA.csv"))
                     
```

## 06.4 Visualize PSA results
```{r}
# Load data and prepare

# Read PSA data from "output" folder
#psa_seq_results <- read.csv(here::here("output", "results_psa_ni5000_nsim5000.csv")) # NB. nsim is actually 1000

# Read the PSA data from Posit Workbench
raw_lines       <- readLines(here::here("output", "results_psa_ni5000_nsim5000.csv")) # NB. nsim is actually 1000
clean_lines     <- gsub("\\\"", "", raw_lines)
temp_file       <- tempfile(fileext = ".csv")
writeLines(clean_lines, temp_file)
psa_seq_results <- read.csv(temp_file, header = TRUE)  
psa_seq_results$i <- rep(seq(1,1000,by=1), 64)

wtp <- 20000

# Rewrite data frame with incremental values compared to the reference treatment
reference_treatment_name <- "AAD-AAD-AAD-AAD-AAD-AAD" 
psa_seq_results_vsAAD <- psa_seq_results %>%
  group_by(i) %>%
  mutate(
    reference_cost = costs[treatment == reference_treatment_name][1],
    reference_effect = effects[treatment == reference_treatment_name][1],
    incremental_cost = costs - reference_cost,
    incremental_effect = effects - reference_effect,
    iNHB = incremental_effect-(incremental_cost/wtp),
    reference_treatment = reference_treatment_name
  ) %>%
  ungroup()

# Create a summary of the results
psa_summary_vsAAD <- data.frame(cost_mean = aggregate(costs ~ treatment, psa_seq_results_vsAAD, mean),
                                cost_se   = aggregate(costs ~ treatment, psa_seq_results_vsAAD, sd),
                                QALY_mean = aggregate(effects ~ treatment, psa_seq_results_vsAAD, mean),
                                QALY_se   = aggregate(effects ~ treatment, psa_seq_results_vsAAD, sd),
                                iNHB_mean = aggregate(iNHB ~ treatment, psa_seq_results_vsAAD, mean),
                                iNHB_se   = aggregate(iNHB ~ treatment, psa_seq_results_vsAAD, sd))

psa_summary_vsAAD           <- psa_summary_vsAAD[, -c(3,5,7,9,11,13)] # remove copies of treatment name columns
colnames(psa_summary_vsAAD) <- c("Treatment_sequence", "Cost",  "Cost se", "QALYs", "QALYs se", "iNHB", "iNHB se" )

# CEAC 
# Create a proper iteration index
psa_seq_results_vsAAD <- psa_seq_results_vsAAD %>%
  dplyr::arrange(treatment) %>%
  dplyr::group_by(treatment) %>%
  dplyr::mutate(i = seq_along(treatment)) %>%
  dplyr::ungroup()

# Remove rows where treatment equals reference_treatment_name
psa_seq_results_vsAAD <- psa_seq_results_vsAAD[psa_seq_results_vsAAD$treatment != reference_treatment_name, ]

which_psa <- psa_seq_results_vsAAD
# Extract unique comparators
comparators <- unique(which_psa$treatment)
n_sim <- length(which_psa$costs) / length(comparators)

# Create a generic CEAC function
calculate_CEAC <- function(comp_name, df, thresholds, n_sim) {
  # Filter data for this comparator
  comp_data <- df[df$treatment == comp_name, ]
  
  # Calculate probability for each threshold
  probs <- sapply(thresholds, function(x) {
    sum(((x * comp_data$incremental_effect) - comp_data$incremental_cost) > 0) / n_sim
  })
  
  return(probs)
}

# Generate thresholds
thresholds <- seq(from = 0, to = 200000, by = 10)

# Create empty data frame for results
CEAC_data <- data.frame(thresholds = thresholds)

# Calculate CEAC for each comparator
for (comp in comparators) {
  # Clean up comparator name for column naming
  col_name <- paste0("prob_", gsub("[^[:alnum:]]", "_", comp))
  
  # Calculate and add to data frame
  CEAC_data[[col_name]] <- calculate_CEAC(comp, which_psa, thresholds, n_sim)
}

# Reshape to long format for ggplot
CEAC_data_l <- gather(CEAC_data, Line, prob, -thresholds)

# Clean up the Line names for the legend
CEAC_data_l$Line <- gsub("prob_", "", CEAC_data_l$Line)
CEAC_data_l$Line <- gsub("_", " ", CEAC_data_l$Line)

# Create CEAC plot
ggplot(data = CEAC_data_l,
       aes(x = thresholds, y = prob, color = Line)) + 
  geom_line(lwd = 1) +  
  coord_cartesian(xlim = c(0, 200000), ylim = c(0, 1)) +
  #scale_y_continuous(breaks = seq(0, 1, .2)) +
  #scale_x_continuous(breaks = seq(0, 200000, 50000), 
  #                   labels = dollar_format(prefix="")) +
  theme_bw(base_size = 10) +
  theme(legend.position = "none") +
  xlab("Maximum willingness to pay threshold for a QALY gained") + 
  ylab("Probability that sequence is optimal") +
  guides(color = guide_legend(title = ""))

#ggsave(here::here("output", "CEAC AF.png"), bg = "white", width = 20, height = 12, units = c("cm"), dpi = 300)

# Display results at specific thresholds
specific_thresholds <- c(20000, 50000, 80000)
ceac_threshold_res <- t(CEAC_data[which(CEAC_data$thresholds == 20000), ])
ceac_threshold_res <- as.data.frame(ceac_threshold_res[-1,])
ceac_threshold_res$treatment <- rownames(ceac_threshold_res)
rownames(ceac_threshold_res) <- NULL
colnames(ceac_threshold_res) <- c("Probability of being cost-effective vs only AADs", "Treatment_sequence")

ceac_threshold_res$Treatment_sequence <- gsub("^prob_", "", ceac_threshold_res$Treatment_sequence)  # Remove "prob_" at the start
ceac_threshold_res$Treatment_sequence <- gsub("_", "-", ceac_threshold_res$Treatment_sequence)      # Replace _ with -
View(ceac_threshold_res)

#probability per threhold
idbc <- psa_seq_results$effects[psa_seq_results$treatment == "AAD-AAD-AAD-AAD-AAD-AAD"]
write.csv(idbc, file = here::here("output", "iDBC_input_noCA_sequence.csv"))


```

### Cost-effectiveness planes (CE-plane) and cost-effectiveness acceptability curves (CEAC)
#### Most CE versus only AADs
```{r}
df_psa1 <- psa_seq_results_vsAAD[psa_seq_results_vsAAD$treatment == "CA-AAD-AAD-AAD-AAD-CA",] 

# CE-plane
library(scales)
ggplot(df_psa1, aes(x=incremental_effect, y=incremental_cost)) +
  geom_point(size = 1.2, shape = 16, color = "#49870c") +
  #stat_ellipse(size = 1, color = "darkblue") +
  scale_y_continuous(name="", labels = dollar_format(prefix = "", big.mark=",", decimal.mark = ".")) +
  ylab("Costs") +
  xlab("QALYs") +
  geom_vline(xintercept = 0)+
  geom_hline(yintercept = 0)+
  geom_abline(intercept = 0, slope = 20000, linetype="dashed", lwd=1)+
  annotate("text", x = 0.2, y = 10000, label = "20,000/QALY threshold")+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5), 
        plot.subtitle = element_text(hjust = 0.5), 
        plot.caption = element_text(hjust = 0.5)) + 
  labs(title = "Cost-effectiveness plane",
       subtitle = paste("Most cost-effective versus", reference_treatment_name))
ggsave(here::here("visual output", "Most cost-effective AAD vs CA.jpg"), width = 20, height = 12, units = c("cm"), dpi = 300)

# CEAC
n_sim       <- 1000
inc_effects <- df_psa1$incremental_effect
inc_costs   <-  df_psa1$incremental_cost

 CEAC = function(x){
  sum((((x*inc_effects)-inc_costs) > 0)/n_sim)
}
 
    thresholds <- matrix(seq(from=0, to=200000, by=10),
                         nrow=20001,
                         ncol=1)
 
    prob <- apply(thresholds, 1, CEAC)
 
# Combine data from line 1 and 2 into 1 dataframe    
CEAC_data <- data.frame("thresholds" = thresholds,
                        "prob" = prob)    
# Create CEAC
ggplot(data = CEAC_data,
       aes(x = thresholds, y = prob)) + geom_line(lwd = 1) +  
       coord_cartesian(xlim = c(0, 200000), ylim = c(0, 1)) +
       scale_y_continuous(breaks = seq(0, 1, .2)) +
       scale_x_continuous(breaks = seq(0, 200000, 50000), labels = dollar_format(prefix="")) +
       theme_bw(base_size = 10)+
       xlab("Maximum willingness to pay threshold for a QALY gained") + ylab("Probability that sequence is optimal") +
       guides(color=guide_legend(title=""))

CEAC_data[which(CEAC_data$thresholds==20000), ]
#CEAC_data[which(CEAC_data$thresholds==50000), ]
#CEAC_data[which(CEAC_data$thresholds==80000), ]
```

### All sequences versus most CE
```{r}
# Calculate incremental results all treatments versus most cost-effective
reference_treatment_name <- "CA-AAD-AAD-AAD-AAD-CA" #Define reference treatment for PSA here
psa_seq_results_vsmostCE <- psa_seq_results %>%
  group_by(i) %>%
  mutate(
    reference_cost = costs[treatment == reference_treatment_name][1],
    reference_effect = effects[treatment == reference_treatment_name][1],
    incremental_cost = costs - reference_cost,
    incremental_effect = effects - reference_effect,
    iNHB = incremental_effect-(incremental_cost/wtp),
    reference_treatment = reference_treatment_name
  ) %>%
  ungroup()

# Create a summary of the results
psa_summary_vsmostCE <- data.frame(cost_mean  = aggregate(costs ~ treatment, psa_seq_results_vsmostCE, mean),
                                   cost_se    = aggregate(costs ~ treatment, psa_seq_results_vsmostCE, sd),
                                   QALY_mean  = aggregate(effects ~ treatment, psa_seq_results_vsmostCE, mean),
                                   QALY_se    = aggregate(effects ~ treatment, psa_seq_results_vsmostCE, sd),
                                   iNHB_mean  = aggregate(iNHB ~ treatment, psa_seq_results_vsmostCE, mean),
                                   iNHB_se    = aggregate(iNHB ~ treatment, psa_seq_results_vsmostCE, sd))

psa_summary_vsmostCE <- psa_summary_vsmostCE[, -c(3,5,7,9,11,13)] # remove copies of treatment name columns
colnames(psa_summary_vsmostCE) <- c("Treatment_sequence", "Cost", "Cost se", "QALYs", "QALYs se", "iNHB", "iNHB se")

# CE-plane
ggplot(psa_seq_results_vsmostCE, aes(x=incremental_effect, y=incremental_cost, colour=treatment)) +
  geom_point(size = 1, shape = 16) +
  scale_y_continuous(name="Incremental costs", labels = dollar_format(prefix = "", big.mark=",", decimal.mark = ".")) +
  xlab("Incremental QALYs") +
  geom_vline(xintercept = 0)+
  geom_hline(yintercept = 0)+
  geom_abline(intercept = 0, slope = 20000, linetype="dashed", lwd=1)+
  annotate("text", x = -0.18, y = -7000, label = "20,000/QALY threshold", size = 3)+
  theme_minimal()+
  theme(legend.position = "none") +
labs(title = "Cost-effectiveness plane", 
       subtitle = "Cost-effectiveness of alternatives vs most-cost effective sequence (CA-AAD-AAD-AAD-AAD-CA)")
#ggsave(here::here("visual output", "CE-plane vs CA-AAD-AAD-AAD-AAD-CA.png"), width = 50, height = 15, units = c("cm"), dpi = 300)

# CEAC 
# Create a proper iteration index
psa_seq_results_vsmostCE <- psa_seq_results_vsmostCE %>%
  dplyr::arrange(treatment) %>%
  dplyr::group_by(treatment) %>%
  dplyr::mutate(i = seq_along(treatment)) %>%
  dplyr::ungroup()

# Remove rows where treatment equals reference_treatment_name
#psa_seq_results_vsmostCE <- psa_seq_results_vsmostCE[psa_seq_results_vsmostCE$treatment != reference_treatment_name, ]

which_psa <- psa_seq_results_vsmostCE
# Extract unique comparators
comparators <- unique(which_psa$treatment)
n_sim <- length(which_psa$costs) / length(comparators)

# Create a generic CEAC function
calculate_CEAC <- function(comp_name, df, thresholds, n_sim) {
  # Filter data for this comparator
  comp_data <- df[df$treatment == comp_name, ]
  
  # Calculate probability for each threshold
  probs <- sapply(thresholds, function(x) {
    sum(((x * comp_data$incremental_effect) - comp_data$incremental_cost) > 0) / n_sim
  })
  
  return(probs)
}

# Generate thresholds
thresholds <- seq(from = 0, to = 200000, by = 10)

# Create empty data frame for results
CEAC_data <- data.frame(thresholds = thresholds)

# Calculate CEAC for each comparator
for (comp in comparators) {
  # Clean up comparator name for column naming
  col_name <- paste0("prob_", gsub("[^[:alnum:]]", "_", comp))
  
  # Calculate and add to data frame
  CEAC_data[[col_name]] <- calculate_CEAC(comp, which_psa, thresholds, n_sim)
}

# Reshape to long format for ggplot
CEAC_data_l <- gather(CEAC_data, Line, prob, -thresholds)

# Clean up the Line names for the legend
CEAC_data_l$Line <- gsub("prob_", "", CEAC_data_l$Line)
CEAC_data_l$Line <- gsub("_", " ", CEAC_data_l$Line)

# Create CEAC plot
ggplot(data = CEAC_data_l,
       aes(x = thresholds, y = prob, color = Line)) + 
  geom_line(lwd = 1) +  
  coord_cartesian(xlim = c(0, 200000), ylim = c(0, 1)) +
  #scale_y_continuous(breaks = seq(0, 1, .2)) +
  #scale_x_continuous(breaks = seq(0, 200000, 50000), 
  #                   labels = dollar_format(prefix="")) +
  theme_bw(base_size = 10) +
  theme(legend.position = "none") +
  xlab("Maximum willingness to pay threshold for a QALY gained") + 
  ylab("Probability that sequence is optimal") +
  guides(color = guide_legend(title = ""))

#ggsave(here::here("output", "CEAC AF.png"), bg = "white", width = 20, height = 12, units = c("cm"), dpi = 300)

# Display results at specific thresholds
specific_thresholds <- c(20000, 50000, 80000)
ceac_threshold_res_vsmostCE <- t(CEAC_data[which(CEAC_data$thresholds == 20000), ])
ceac_threshold_res_vsmostCE <- as.data.frame(ceac_threshold_res_vsmostCE[-1,])
ceac_threshold_res_vsmostCE$treatment <- rownames(ceac_threshold_res_vsmostCE)
rownames(ceac_threshold_res_vsmostCE) <- NULL
colnames(ceac_threshold_res_vsmostCE) <- c("Probability of being cost-effective vs most CE", "Treatment_sequence")

ceac_threshold_res_vsmostCE$Treatment_sequence <- gsub("^prob_", "", ceac_threshold_res_vsmostCE$Treatment_sequence)  # Remove "prob_" at the start
ceac_threshold_res_vsmostCE$Treatment_sequence <- gsub("_", "-", ceac_threshold_res_vsmostCE$Treatment_sequence)      # Replace _ with -
#View(ceac_threshold_res_vsmostCE)

psa_results_with_prob2 <- psa_summary_vsAAD %>%
  inner_join(ceac_threshold_res, by = "Treatment_sequence") %>%
  inner_join(ceac_threshold_res_vsmostCE, by = "Treatment_sequence")
View(psa_results_with_prob2)

# Export results to Microsoft Word
library(flextable)
library(officer)

psa_results_with_prob2 <- psa_results_with_prob2 %>%
  arrange(desc(iNHB))

# Create a flextable object
ft <- flextable(psa_results_with_prob2)

# Customize the table (optional)
ft <- autofit(ft)  # Automatically adjust column widths
#ft <- theme_vanilla(ft)  # Apply a theme

ft <- colformat_double(ft, j = "Cost", digits = 0, big.mark = ",")   
ft <- colformat_double(ft, j = "Cost se", digits = 0, big.mark = ",")   
ft <- colformat_double(ft, j = "QALYs", digits = 3)   
ft <- colformat_double(ft, j = "QALYs se", digits = 3)   
ft <- colformat_double(ft, j = "iNHB", digits = 3) 
ft <- colformat_double(ft, j = "iNHB se", digits = 3) 
ft <- colformat_double(ft, j = "Probability of being cost-effective vs only AADs", digits = 3)   
ft <- colformat_double(ft, j = "Probability of being cost-effective vs most CE", digits = 3)   

# Save to Word document
doc <- read_docx()  # Create a new Word document
doc <- body_add_flextable(doc, value = ft)  # Add the table to the document
print(doc, target = here::here("output", "PSA_results_vs_most_CE.docx"))  # Save the document




```

```{r}
# Grouped comparison, first line CA vs first line AAD
df_psa3 <- cbind(psa_seq_results[, 1], separate(psa_seq_results, col = "treatment", c("L1","L2","L3", "L4", "L5", "L6"), "-"))
df_psa3 <- df_psa3[,-2]
df_psa3 <- df_psa3 %>%
  mutate(L1 = factor(L1, levels = c("AAD", "CA"))) %>%
  arrange(L1)
df_psa3$i <- rep(seq(1,32000,by=1), 2)
df_psa3 <- df_psa3 %>%
  group_by(i) %>%
  mutate(
    reference_cost = costs[L1 == "AAD"],
    reference_effect = effects[L1 == "AAD"],
    incremental_cost = costs - reference_cost,
    incremental_effect = effects - reference_effect,
    iNHB = incremental_effect-(incremental_cost/wtp),
    reference_treatment = "First line AAD"
  ) %>%
  ungroup()
df_psa3 <- df_psa3[df_psa3$L1 == "CA",]
sum(df_psa3$iNHB > 0) / nrow(df_psa3)


ggplot(df_psa3, aes(x=incremental_effect, y=incremental_cost, colour=L1)) +
  geom_point(size = 1, shape = 16, color = "#49870c") +
  scale_y_continuous(name="Incremental costs", labels = dollar_format(prefix = "", big.mark=",", decimal.mark = ".")) +
  xlab("Incremental QALYs") +
  geom_vline(xintercept = 0)+
  geom_hline(yintercept = 0)+
  geom_abline(intercept = 0, slope = 20000, linetype="dashed", lwd=1)+
  annotate("text", x = 0.35, y = 4500, label = "20,000/QALY threshold", size = 3)+
  theme_minimal()+
labs(title = "Cost-effectiveness plane", 
       subtitle = "Grouped comparison of CA in first line vs. AAD in first line")
ggsave(here::here("visual output", "grouped CA in first line vs AAD in first line.jpg"), width = 20, height = 12, units = c("cm"), dpi = 300)

```

```{r}
# Grouped comparison, by number of CA's (note, compare with CA-AAD-AAD-AAD-AAD-AAD)
df_psa4 <- cbind(psa_seq_results[, 1], separate(psa_seq_results, col = "treatment", c("L1","L2","L3", "L4", "L5", "L6"), "-"))
df_psa4 <- df_psa4[,-2]
df_psa4$n_ca <- apply(df_psa4[, c("L1", "L2", "L3", "L4", "L5", "L6")], 1, 
                      function(x) sum(x == "CA"))
df_psa4$n_ca_afterfirst <- df_psa4$n_ca -1
df_psa4 <- df_psa4[df_psa4$n_ca > 1,]
df_psa4 <- df_psa4[df_psa4$L1 != "AAD",]

# Plot NHB boxplot
ggplot(df_psa4, aes(x = factor(n_ca_afterfirst), y = iNHB, fill = factor(n_ca_afterfirst))) +
  geom_boxplot()+
  #scale_y_continuous(limits = quantile(df_psa4$NHB, c(0.1, 0.9))) +
  xlab("Number of additional CA's after the first") +
  geom_hline(yintercept = 0, col = "red", linetype = "dashed") +
  theme_minimal() +
  labs(title = "Incremental net health benefit", 
       subtitle = "Grouped comparison of number of CA's after the first")

ggsave(here::here("visual output", "Grouped boxplot by number of CA's in sequence.jpg"), width = 20, height = 12, units = c("cm"), dpi = 300)

# Report proportion with positive iNHB
sum(df_psa4$iNHB[df_psa4$n_ca_afterfirst == 1] > 0) / length(df_psa4$iNHB[df_psa4$n_ca_afterfirst == 1])
sum(df_psa4$iNHB[df_psa4$n_ca_afterfirst == 2] > 0) / length(df_psa4$iNHB[df_psa4$n_ca_afterfirst == 2])
sum(df_psa4$iNHB[df_psa4$n_ca_afterfirst == 3] > 0) / length(df_psa4$iNHB[df_psa4$n_ca_afterfirst == 3])
sum(df_psa4$iNHB[df_psa4$n_ca_afterfirst == 4] > 0) / length(df_psa4$iNHB[df_psa4$n_ca_afterfirst == 4])
sum(df_psa4$iNHB[df_psa4$n_ca_afterfirst == 5] > 0) / length(df_psa4$iNHB[df_psa4$n_ca_afterfirst == 5])

```

```{r}
# Boxplot of timing of CA after first line AAD
psa_seq_results$i <- rep(seq(1,1000,by=1), 64)
reference_treatment_name <- "CA-AAD-AAD-AAD-AAD-AAD" #Define reference treatment for PSA here
psa_seq_results3 <- psa_seq_results %>%
  group_by(i) %>%
  mutate(
    reference_cost = costs[treatment == reference_treatment_name][1],
    reference_effect = effects[treatment == reference_treatment_name][1],
    incremental_cost = costs - reference_cost,
    incremental_effect = effects - reference_effect,
    iNHB = incremental_effect-(incremental_cost/wtp),
    reference_treatment = reference_treatment_name
  ) %>%
  ungroup()

df_psa7 <- cbind(psa_seq_results3[, 1], separate(psa_seq_results3, col = "treatment", c("L1","L2","L3", "L4", "L5", "L6"), "-"))
df_psa7 <- df_psa7[,-2]
df_psa7 <- df_psa7[df_psa7$L1 == "AAD",]

df_psa7 <- df_psa7 %>%   mutate(     
  # Check if CA appears in L2 or L3     
  early_CA = (L2 == "CA" | L3 == "CA"),     
  # Check if CA appears in L4, L5, or L6     
  late_CA = (L4 == "CA" | L5 == "CA" | L6 == "CA"),     
  # Create grouping variable     
  CA_timing = case_when(       
    early_CA & !late_CA ~ "Early CA (L2/L3 only)",      
    !early_CA & late_CA ~ "Late CA (L4/L5/L6 only)",      
    early_CA & late_CA ~ "Both early and late CA (L2/L3 and L4/L5/L6)",       
    !early_CA & !late_CA ~ "No CA"     )   )

ggplot(df_psa7, aes(x = factor(CA_timing), y = iNHB, fill = factor(CA_timing))) +
  geom_boxplot()+
  geom_hline(yintercept = 0, col = "red", linetype = "dashed") +
  theme_minimal() +
  labs(title = "Incremental net health benefit", 
       subtitle = paste("Grouped comparison of timing of CAs after first line AAD \n versus", reference_treatment_name),
       fill = "Timing of CAs")  +
  theme(     
    axis.title.x = element_blank(),  # Remove x-axis title     
    axis.text.x = element_blank()    # Remove x-axis labels   
    )
ggsave(here::here("visual output", "Grouped boxplot by timing of CA.jpg"), width = 20, height = 12, units = c("cm"), dpi = 300)

# Report proportion with positive iNHB
sum(df_psa7$iNHB[df_psa7$CA_timing == "Both early and late CA (L2/L3 and L4/L5/L6)"] > 0) / length(df_psa7$iNHB[df_psa7$CA_timing == "Both early and late CA (L2/L3 and L4/L5/L6)"])
sum(df_psa7$iNHB[df_psa7$CA_timing == "Early CA (L2/L3 only)"]> 0) / length(df_psa7$iNHB[df_psa7$CA_timing == "Early CA (L2/L3 only)"])
sum(df_psa7$iNHB[df_psa7$CA_timing == "Late CA (L4/L5/L6 only)"] > 0) / length(df_psa7$iNHB[df_psa7$CA_timing == "Late CA (L4/L5/L6 only)"])
sum(df_psa7$iNHB[df_psa7$CA_timing == "No CA" ]> 0) / length(df_psa7$iNHB[df_psa7$CA_timing == "No CA" ])


```

# 0.9.6 Value of information analysis & population impact
```{R}
knitr::opts_chunk$set(eval = FALSE)
#In this section we first create a new data frame of the PSA results that can be read by the calc_evpi package of dampack
 
# Read the PSA data from Posit Workbench
raw_lines       <- readLines(here::here("output", "results_psa_ni5000_nsim5000.csv")) # NB. nsim is actually 1000
clean_lines     <- gsub("\\\"", "", raw_lines)
temp_file       <- tempfile(fileext = ".csv")
writeLines(clean_lines, temp_file)
psa_seq_results <- read.csv(temp_file, header = TRUE)  
psa_seq_results$i <- rep(seq(1,1000,by=1), 64)

#first make data wide for multiple comparisons
psa_costs <- data.frame(treatment = psa_seq_results$treatment, costs = psa_seq_results$cost, id = psa_seq_results$i)
psa_effects <- data.frame(treatment = psa_seq_results$treatment, effects = psa_seq_results$effects, id = psa_seq_results$i)

psa_wide_costs <- psa_costs %>% pivot_wider(names_from = treatment, values_from = costs)
psa_wide_effects <- psa_effects %>% pivot_wider(names_from = treatment, values_from = effects)
 
###Comparing multiple treatments
df_psa_obj_all <- make_psa_obj(cost = psa_wide_costs[,-1] , 
                           effectiveness =  psa_wide_effects[,-1], 
                           strategies = v_names_str) #note: check with authors of dampack packages, gives error in summary
 
 
###Comparing single treatments
 
#select treatments
df_psa_costs <- data.frame(AADs     = psa_seq_results$costs[psa_seq_results$treatment == "AAD-AAD-AAD-AAD-AAD-AAD"], 
                           mostCE   = psa_seq_results$costs[psa_seq_results$treatment == "CA-AAD-AAD-AAD-AAD-CA"])
df_psa_effects <- data.frame(AADs   = psa_seq_results$effects[psa_seq_results$treatment == "AAD-AAD-AAD-AAD-AAD-AAD"], 
                             mostCE = psa_seq_results$effects[psa_seq_results$treatment ==  "CA-AAD-AAD-AAD-AAD-CA"])
 
 
v_names_str <- c("AAD-AAD-AAD-AAD-AAD-AAD","CA-AAD-AAD-AAD-AAD-CA")
df_psa_obj <- make_psa_obj(cost = df_psa_costs , 
                           effectiveness =  df_psa_effects, 
                           strategies = v_names_str) #note: check with authors of dampack packages, gives error in summary
 
plot(df_psa_obj)
 
wtp <- 20000 

evpi <- calc_evpi(df_psa_obj, wtp, pop = 5618)
icer <- calculate_icers_psa(df_psa_obj)
evpi
icer
plot(evpi)

```

# 07 Test model stability in deterministic setting
In this section we loop over a change in the sample size and then check the stability of the calculated iNHB

```{r}
# Function to process a single iteration for a given sample size
process_iteration <- function(i, n_i, l_params, df_X) {
  outcomes_trt1 <- MicroSim(l_params, n_i, df_X, 
                            TRT1 = "AAD", TRT2 = "CA", TRT3 = "AAD", 
                            TRT4 = "AAD", TRT5 = "AAD", TRT6 = "AAD", seed = i)
  
  outcomes_trt2 <- MicroSim(l_params, n_i, df_X, 
                            TRT1 = "AAD", TRT2 = "AAD", TRT3 = "CA", 
                            TRT4 = "AAD", TRT5 = "AAD", TRT6 = "AAD", seed = i)
  
  d_e <- outcomes_trt2$te_hat-outcomes_trt1$te_hat
  d_c <- outcomes_trt2$tc_hat-outcomes_trt1$tc_hat
  iNHB <- d_e - (d_c/wtp)
  
  return(iNHB)
}

# Let op: duurt erg lang (>15 uur) door de 120000 en 150000 aan het eind!
# Main analysis with parallel processing
PSA                <- TRUE  # if TRUE stores less variables for 'faster' computing
iterations         <- 20
n_i_options        <- c(1000, 5000, 10000, 15000, 20000, 30000, 50000, 100000, 120000)
df_iNHB            <- matrix(nrow=iterations, ncol=length(n_i_options))
colnames(df_iNHB)  <- n_i_options

# Setup parallel processing
num_cores          <- detectCores() - 1  # Leave one core free for system processes
cluster            <- makeCluster(num_cores)
registerDoParallel(cluster)

# Export necessary objects to the cluster
clusterExport(cluster, c('MicroSim', 'Create_df_X', 'n_i', 'rtruncnorm', 'v_n', 'n_states',
                         'n_t',  'Costs', 'Effs', 'Probs', 'PrepareProbs', 'PrepareCosts', 
                         'cl', 'v_dwc', 'v_dwe', 'v_wcc', 'min_age', 'max_age', 'PSA',
                         'df_mort', 'beta_reg_attendance', 'beta_reg_presenteeism', 'params_ic_log', 'params_ic_hours', 'mod_splines'))

clusterEvalQ(cluster, 
             {library(dplyr) 
               library(darthtools)
               library(splines)
               source(here::here("functions", "functions.R"))
             })

# Loop over sample sizes
for (j in 1:length(n_i_options)) {
  n_i <- n_i_options[j]
  
  set.seed(2)
  v_age                 <- round(rtruncnorm(n_i, min_age, max_age, age, sd_age)) 
  v_Sex                 <- rbinom(n_i, 1, prop_female) 
  l_params$v_age        <- round(rtruncnorm(n_i, min_age, max_age, age, sd_age))
  l_params$v_Sex         <- rbinom(n_i, 1, prop_female)
  
  # Parallel processing of iterations
  results <- foreach(i = 1:iterations, 
                     .combine = 'c',
                     .packages = c("dplyr", "darthtools")) %dopar% {
                       process_iteration(i, n_i, l_params, df_X)
                     }
  
  df_iNHB[,j] <- results
  cat(paste0(round(j / length(n_i_options) * 100), '% completed\n'))
}

# Stop the cluster
stopCluster(cluster)

save(df_iNHB, file = here::here("output", "df_iNHB.RData"))

#Load previous data here
load(here::here("output", "df_iNHB.RData"))

# Results are stored in df_icers matrix
colnames(df_iNHB) <- c("1,000", "5,000", "10,000", "15,000", "20,000", "30,000", "50,000", "100,000", "120,000")
write.csv(df_iNHB, here::here("output", "check_sample_size.csv"))

data               <- read.csv(here::here("output", "check_sample_size.csv"), header = T)
data               <- data[, -1]
colnames(data) <- c("1,000", "5,000", "10,000", "15,000", "20,000", "30,000", "50,000", "100,000", "120,000")
round(colMeans(data), 3)

# Plot results
data2 <- gather(data = as.data.frame(data), key=size, value = iNHB)


ggplot(data2, aes(x=size, y=iNHB)) + 
  geom_boxplot() +
  ggtitle("Model stability test comparing 2 sequences with 20 seeds") +
  ylab("iNHB")+
  xlab("Number of patients sampled")+
  scale_x_discrete(limits=c("1,000", "5,000", "10,000", "15,000", "20,000", "30,000", "50,000", "100,000", "120,000"))+
  #scale_y_continuous(limits=c(0.75, 0.95))+
  theme_minimal()+
  theme(text=element_text(size=10), axis.text.y = element_text(size = 10), axis.text.x = element_text(size = 10))

ggsave(here::here("output", "check_samplesize_final.jpg"), width = 16, height = 8, units = c("cm"), dpi = 300)

```